.TH "/home/vladn/git/ovs/datapath/linux/vxlan.c" 3 "Mon Aug 17 2015" "ovs datapath" \" -*- nroff -*-
.ad l
.nh
.SH NAME
/home/vladn/git/ovs/datapath/linux/vxlan.c \- 
.SH SYNOPSIS
.br
.PP
\fC#include <linux/version\&.h>\fP
.br
\fC#include <linux/kernel\&.h>\fP
.br
\fC#include <linux/types\&.h>\fP
.br
\fC#include <linux/module\&.h>\fP
.br
\fC#include <linux/errno\&.h>\fP
.br
\fC#include <linux/slab\&.h>\fP
.br
\fC#include <linux/skbuff\&.h>\fP
.br
\fC#include <linux/rculist\&.h>\fP
.br
\fC#include <linux/netdevice\&.h>\fP
.br
\fC#include <linux/in\&.h>\fP
.br
\fC#include <linux/ip\&.h>\fP
.br
\fC#include <linux/udp\&.h>\fP
.br
\fC#include <linux/igmp\&.h>\fP
.br
\fC#include <linux/etherdevice\&.h>\fP
.br
\fC#include <linux/if_ether\&.h>\fP
.br
\fC#include <linux/if_vlan\&.h>\fP
.br
\fC#include <linux/hash\&.h>\fP
.br
\fC#include <linux/ethtool\&.h>\fP
.br
\fC#include <net/arp\&.h>\fP
.br
\fC#include <net/ndisc\&.h>\fP
.br
\fC#include <net/ip\&.h>\fP
.br
\fC#include <net/gre\&.h>\fP
.br
\fC#include <net/ip_tunnels\&.h>\fP
.br
\fC#include <net/icmp\&.h>\fP
.br
\fC#include <net/udp\&.h>\fP
.br
\fC#include <net/udp_tunnel\&.h>\fP
.br
\fC#include <net/rtnetlink\&.h>\fP
.br
\fC#include <net/route\&.h>\fP
.br
\fC#include <net/dsfield\&.h>\fP
.br
\fC#include <net/inet_ecn\&.h>\fP
.br
\fC#include <net/net_namespace\&.h>\fP
.br
\fC#include <net/netns/generic\&.h>\fP
.br
\fC#include <net/vxlan\&.h>\fP
.br
\fC#include 'compat\&.h'\fP
.br
\fC#include 'datapath\&.h'\fP
.br
\fC#include 'gso\&.h'\fP
.br
\fC#include 'vlan\&.h'\fP
.br

.SS "Data Structures"

.in +1c
.ti -1c
.RI "struct \fBvxlanhdr\fP"
.br
.in -1c
.SS "Macros"

.in +1c
.ti -1c
.RI "#define \fBpr_fmt\fP(fmt)   KBUILD_MODNAME ': ' fmt"
.br
.in -1c
.SS "Functions"

.in +1c
.ti -1c
.RI "static int \fBvxlan_udp_encap_recv\fP (struct sock *sk, struct sk_buff *skb)"
.br
.ti -1c
.RI "static void \fBvxlan_sock_put\fP (struct sk_buff *skb)"
.br
.ti -1c
.RI "static void \fBvxlan_set_owner\fP (struct sock *sk, struct sk_buff *skb)"
.br
.ti -1c
.RI "static void \fBvxlan_build_gbp_hdr\fP (struct \fBvxlanhdr\fP *vxh, u32 vxflags, struct \fBvxlan_metadata\fP *md)"
.br
.ti -1c
.RI "int \fBrpl_vxlan_xmit_skb\fP (struct \fBvxlan_sock\fP *vs, struct rtable *rt, struct sk_buff *skb, __be32 \fBsrc\fP, __be32 \fBdst\fP, __u8 \fBtos\fP, __u8 \fBttl\fP, __be16 df, __be16 src_port, __be16 dst_port, struct \fBvxlan_metadata\fP *md, \fBbool\fP xnet, u32 vxflags)"
.br
.ti -1c
.RI "\fBEXPORT_SYMBOL_GPL\fP (\fBrpl_vxlan_xmit_skb\fP)"
.br
.ti -1c
.RI "static void \fBrcu_free_vs\fP (struct rcu_head *rcu)"
.br
.ti -1c
.RI "static void \fBvxlan_del_work\fP (struct work_struct *work)"
.br
.ti -1c
.RI "static struct socket * \fBvxlan_create_sock\fP (struct net *net, \fBbool\fP \fBipv6\fP, __be16 port, u32 \fBflags\fP)"
.br
.ti -1c
.RI "static struct \fBvxlan_sock\fP * \fBvxlan_socket_create\fP (struct net *net, __be16 port, \fBvxlan_rcv_t\fP *rcv, void *data, u32 \fBflags\fP)"
.br
.ti -1c
.RI "struct \fBvxlan_sock\fP * \fBrpl_vxlan_sock_add\fP (struct net *net, __be16 port, \fBvxlan_rcv_t\fP *rcv, void *data, \fBbool\fP no_share, u32 \fBflags\fP)"
.br
.ti -1c
.RI "\fBEXPORT_SYMBOL_GPL\fP (\fBrpl_vxlan_sock_add\fP)"
.br
.ti -1c
.RI "void \fBrpl_vxlan_sock_release\fP (struct \fBvxlan_sock\fP *vs)"
.br
.ti -1c
.RI "\fBEXPORT_SYMBOL_GPL\fP (\fBrpl_vxlan_sock_release\fP)"
.br
.in -1c
.SH "Macro Definition Documentation"
.PP 
.SS "#define pr_fmt(fmt)   KBUILD_MODNAME ': ' fmt"

.SH "Function Documentation"
.PP 
.SS "EXPORT_SYMBOL_GPL (\fBrpl_vxlan_xmit_skb\fP)"

.SS "EXPORT_SYMBOL_GPL (\fBrpl_vxlan_sock_add\fP)"

.SS "EXPORT_SYMBOL_GPL (\fBrpl_vxlan_sock_release\fP)"

.SS "static void rcu_free_vs (struct rcu_head * rcu)\fC [static]\fP"

.PP
.nf
231 {
232     struct vxlan_sock *vs = container_of(rcu, struct vxlan_sock, rcu);
233 
234     kfree(vs);
235 }
.fi
.SS "struct \fBvxlan_sock\fP* rpl_vxlan_sock_add (struct net * net, __be16 port, \fBvxlan_rcv_t\fP * rcv, void * data, \fBbool\fP no_share, u32 flags)"

.PP
.nf
314 {
315     return vxlan_socket_create(net, port, rcv, data, flags);
316 }
.fi
.SS "void rpl_vxlan_sock_release (struct \fBvxlan_sock\fP * vs)"

.PP
.nf
320 {
321     ASSERT_OVSL();
322 
323     queue_work(system_wq, &vs->del_work);
324 }
.fi
.SS "int rpl_vxlan_xmit_skb (struct \fBvxlan_sock\fP * vs, struct rtable * rt, struct sk_buff * skb, __be32 src, __be32 dst, __u8 tos, __u8 ttl, __be16 df, __be16 src_port, __be16 dst_port, struct \fBvxlan_metadata\fP * md, \fBbool\fP xnet, u32 vxflags)"

.PP
.nf
188 {
189     struct vxlanhdr *vxh;
190     int min_headroom;
191     int err;
192     bool udp_sum = !!(vxflags & VXLAN_F_UDP_CSUM);
193 
194     min_headroom = LL_RESERVED_SPACE(rt_dst(rt)\&.dev) + rt_dst(rt)\&.header_len
195             + VXLAN_HLEN + sizeof(struct iphdr)
196             + (skb_vlan_tag_present(skb) ? VLAN_HLEN : 0);
197 
198     /* Need space for new headers (invalidates iph ptr) */
199     err = skb_cow_head(skb, min_headroom);
200     if (unlikely(err)) {
201         kfree_skb(skb);
202         return err;
203     }
204 
205     skb = vlan_hwaccel_push_inside(skb);
206     if (WARN_ON(!skb))
207         return -ENOMEM;
208 
209     skb = udp_tunnel_handle_offloads(skb, udp_sum, true);
210     if (IS_ERR(skb))
211         return PTR_ERR(skb);
212 
213     vxh = (struct vxlanhdr *) __skb_push(skb, sizeof(*vxh));
214     vxh->vx_flags = htonl(VXLAN_HF_VNI);
215     vxh->vx_vni = md->vni;
216 
217     if (vxflags & VXLAN_F_GBP)
218         vxlan_build_gbp_hdr(vxh, vxflags, md);
219 
220     vxlan_set_owner(vs->sock->sk, skb);
221 
222     ovs_skb_set_inner_protocol(skb, htons(ETH_P_TEB));
223 
224     return udp_tunnel_xmit_skb(rt, skb, src, dst, tos,
225                    ttl, df, src_port, dst_port, xnet,
226                    !udp_sum);
227 }
.fi
.SS "static void vxlan_build_gbp_hdr (struct \fBvxlanhdr\fP * vxh, u32 vxflags, struct \fBvxlan_metadata\fP * md)\fC [static]\fP"

.PP
.nf
165 {
166     struct vxlanhdr_gbp *gbp;
167 
168     if (!md->gbp)
169         return;
170 
171     gbp = (struct vxlanhdr_gbp *)vxh;
172     vxh->vx_flags |= htonl(VXLAN_HF_GBP);
173 
174     if (md->gbp & VXLAN_GBP_DONT_LEARN)
175         gbp->dont_learn = 1;
176 
177     if (md->gbp & VXLAN_GBP_POLICY_APPLIED)
178         gbp->policy_applied = 1;
179 
180     gbp->policy_id = htons(md->gbp & VXLAN_GBP_ID_MASK);
181 }
.fi
.SS "static struct socket* vxlan_create_sock (struct net * net, \fBbool\fP ipv6, __be16 port, u32 flags)\fC [static]\fP"

.PP
.nf
247 {
248     struct socket *sock;
249     struct udp_port_cfg udp_conf;
250     int err;
251 
252     memset(&udp_conf, 0, sizeof(udp_conf));
253 
254     if (ipv6) {
255         udp_conf\&.family = AF_INET6;
256         /* The checksum flag is silently ignored but it
257          * doesn't make sense here anyways because OVS enables
258          * checksums on a finer granularity than per-socket\&.
259          */
260     } else {
261         udp_conf\&.family = AF_INET;
262         udp_conf\&.local_ip\&.s_addr = htonl(INADDR_ANY);
263     }
264 
265     udp_conf\&.local_udp_port = port;
266 
267     /* Open UDP socket */
268     err = udp_sock_create(net, &udp_conf, &sock);
269     if (err < 0)
270         return ERR_PTR(err);
271 
272     return sock;
273 }
.fi
.SS "static void vxlan_del_work (struct work_struct * work)\fC [static]\fP"

.PP
.nf
238 {
239     struct vxlan_sock *vs = container_of(work, struct vxlan_sock, del_work);
240 
241     udp_tunnel_sock_release(vs->sock);
242     call_rcu(&vs->rcu, rcu_free_vs);
243 }
.fi
.SS "static void vxlan_set_owner (struct sock * sk, struct sk_buff * skb)\fC [static]\fP"

.PP
.nf
156 {
157     skb_orphan(skb);
158     sock_hold(sk);
159     skb->sk = sk;
160     skb->destructor = vxlan_sock_put;
161 }
.fi
.SS "static void vxlan_sock_put (struct sk_buff * skb)\fC [static]\fP"

.PP
.nf
150 {
151     sock_put(skb->sk);
152 }
.fi
.SS "static struct \fBvxlan_sock\fP* vxlan_socket_create (struct net * net, __be16 port, \fBvxlan_rcv_t\fP * rcv, void * data, u32 flags)\fC [static]\fP"

.PP
.nf
277 {
278     struct vxlan_sock *vs;
279     struct socket *sock;
280     struct udp_tunnel_sock_cfg tunnel_cfg;
281 
282     vs = kmalloc(sizeof(*vs), GFP_KERNEL);
283     if (!vs) {
284         pr_debug("memory alocation failure\n");
285         return ERR_PTR(-ENOMEM);
286     }
287 
288     INIT_WORK(&vs->del_work, vxlan_del_work);
289 
290     sock = vxlan_create_sock(net, false, port, flags);
291     if (IS_ERR(sock)) {
292         kfree(vs);
293         return ERR_CAST(sock);
294     }
295 
296     vs->sock = sock;
297     vs->rcv = rcv;
298     vs->data = data;
299     vs->flags = (flags & VXLAN_F_RCV_FLAGS);
300 
301     tunnel_cfg\&.sk_user_data = vs;
302     tunnel_cfg\&.encap_type = 1;
303     tunnel_cfg\&.encap_rcv = vxlan_udp_encap_recv;
304     tunnel_cfg\&.encap_destroy = NULL;
305 
306     setup_udp_tunnel_sock(net, sock, &tunnel_cfg);
307 
308     return vs;
309 }
.fi
.SS "static int vxlan_udp_encap_recv (struct sock * sk, struct sk_buff * skb)\fC [static]\fP"

.PP
.nf
73 {
74     struct vxlan_sock *vs;
75     struct vxlanhdr *vxh;
76     u32 flags, vni;
77     struct vxlan_metadata md = {0};
78 
79     /* Need Vxlan and inner Ethernet header to be present */
80     if (!pskb_may_pull(skb, VXLAN_HLEN))
81         goto error;
82 
83     vxh = (struct vxlanhdr *)(udp_hdr(skb) + 1);
84     flags = ntohl(vxh->vx_flags);
85     vni = ntohl(vxh->vx_vni);
86 
87     if (flags & VXLAN_HF_VNI) {
88         flags &= ~VXLAN_HF_VNI;
89     } else {
90         /* VNI flag always required to be set */
91         goto bad_flags;
92     }
93 
94     if (iptunnel_pull_header(skb, VXLAN_HLEN, htons(ETH_P_TEB)))
95         goto drop;
96 
97     vs = rcu_dereference_sk_user_data(sk);
98     if (!vs)
99         goto drop;
100 
101     /* For backwards compatibility, only allow reserved fields to be
102     * used by VXLAN extensions if explicitly requested\&.
103     */
104     if ((flags & VXLAN_HF_GBP) && (vs->flags & VXLAN_F_GBP)) {
105         struct vxlanhdr_gbp *gbp;
106 
107         gbp = (struct vxlanhdr_gbp *)vxh;
108         md\&.gbp = ntohs(gbp->policy_id);
109 
110         if (gbp->dont_learn)
111             md\&.gbp |= VXLAN_GBP_DONT_LEARN;
112 
113         if (gbp->policy_applied)
114             md\&.gbp |= VXLAN_GBP_POLICY_APPLIED;
115 
116         flags &= ~VXLAN_GBP_USED_BITS;
117     }
118 
119     if (flags || (vni & 0xff)) {
120         /* If there are any unprocessed flags remaining treat
121         * this as a malformed packet\&. This behavior diverges from
122         * VXLAN RFC (RFC7348) which stipulates that bits in reserved
123         * in reserved fields are to be ignored\&. The approach here
124         * maintains compatbility with previous stack code, and also
125         * is more robust and provides a little more security in
126         * adding extensions to VXLAN\&.
127         */
128 
129         goto bad_flags;
130     }
131 
132     md\&.vni = vxh->vx_vni;
133     vs->rcv(vs, skb, &md);
134     return 0;
135 
136 drop:
137     /* Consume bad packet */
138     kfree_skb(skb);
139     return 0;
140 bad_flags:
141     pr_debug("invalid vxlan flags=%#x vni=%#x\n",
142          ntohl(vxh->vx_flags), ntohl(vxh->vx_vni));
143 
144 error:
145     /* Return non vxlan pkt */
146     return 1;
147 }
.fi
.SH "Author"
.PP 
Generated automatically by Doxygen for ovs datapath from the source code\&.
