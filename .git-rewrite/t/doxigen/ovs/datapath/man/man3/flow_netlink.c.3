.TH "/home/vladn/git/ovs/datapath/linux/flow_netlink.c" 3 "Mon Aug 17 2015" "ovs datapath" \" -*- nroff -*-
.ad l
.nh
.SH NAME
/home/vladn/git/ovs/datapath/linux/flow_netlink.c \- 
.SH SYNOPSIS
.br
.PP
\fC#include <linux/uaccess\&.h>\fP
.br
\fC#include <linux/netdevice\&.h>\fP
.br
\fC#include <linux/etherdevice\&.h>\fP
.br
\fC#include <linux/if_ether\&.h>\fP
.br
\fC#include <linux/if_vlan\&.h>\fP
.br
\fC#include <net/llc_pdu\&.h>\fP
.br
\fC#include <linux/kernel\&.h>\fP
.br
\fC#include <linux/jhash\&.h>\fP
.br
\fC#include <linux/jiffies\&.h>\fP
.br
\fC#include <linux/llc\&.h>\fP
.br
\fC#include <linux/module\&.h>\fP
.br
\fC#include <linux/in\&.h>\fP
.br
\fC#include <linux/rcupdate\&.h>\fP
.br
\fC#include <linux/if_arp\&.h>\fP
.br
\fC#include <linux/ip\&.h>\fP
.br
\fC#include <linux/ipv6\&.h>\fP
.br
\fC#include <linux/sctp\&.h>\fP
.br
\fC#include <linux/tcp\&.h>\fP
.br
\fC#include <linux/udp\&.h>\fP
.br
\fC#include <linux/icmp\&.h>\fP
.br
\fC#include <linux/icmpv6\&.h>\fP
.br
\fC#include <linux/rculist\&.h>\fP
.br
\fC#include <net/geneve\&.h>\fP
.br
\fC#include <net/ip\&.h>\fP
.br
\fC#include <net/ipv6\&.h>\fP
.br
\fC#include <net/ndisc\&.h>\fP
.br
\fC#include <net/mpls\&.h>\fP
.br
\fC#include 'datapath\&.h'\fP
.br
\fC#include 'flow\&.h'\fP
.br
\fC#include 'flow_netlink\&.h'\fP
.br
\fC#include 'vport-vxlan\&.h'\fP
.br

.SS "Data Structures"

.in +1c
.ti -1c
.RI "struct \fBovs_len_tbl\fP"
.br
.in -1c
.SS "Macros"

.in +1c
.ti -1c
.RI "#define \fBpr_fmt\fP(fmt)   KBUILD_MODNAME ': ' fmt"
.br
.ti -1c
.RI "#define \fBOVS_ATTR_NESTED\fP   -1"
.br
.ti -1c
.RI "#define \fBSW_FLOW_KEY_PUT\fP(match,  field,  value,  is_mask)"
.br
.ti -1c
.RI "#define \fBSW_FLOW_KEY_MEMCPY_OFFSET\fP(match,  offset,  value_p,  len,  is_mask)"
.br
.ti -1c
.RI "#define \fBSW_FLOW_KEY_MEMCPY\fP(match,  field,  value_p,  len,  is_mask)"
.br
.ti -1c
.RI "#define \fBSW_FLOW_KEY_MEMSET_FIELD\fP(match,  field,  value,  is_mask)"
.br
.ti -1c
.RI "#define \fBMAX_ACTIONS_BUFSIZE\fP   (32 * 1024)"
.br
.in -1c
.SS "Functions"

.in +1c
.ti -1c
.RI "static void \fBupdate_range\fP (struct \fBsw_flow_match\fP *match, size_t offset, size_t size, \fBbool\fP is_mask)"
.br
.ti -1c
.RI "static \fBbool\fP \fBmatch_validate\fP (const struct \fBsw_flow_match\fP *match, u64 key_attrs, u64 mask_attrs, \fBbool\fP log)"
.br
.ti -1c
.RI "size_t \fBovs_tun_key_attr_size\fP (void)"
.br
.ti -1c
.RI "size_t \fBovs_key_attr_size\fP (void)"
.br
.ti -1c
.RI "static \fBbool\fP \fBis_all_zero\fP (const u8 *fp, size_t size)"
.br
.ti -1c
.RI "static int \fB__parse_flow_nlattrs\fP (const struct nlattr *attr, const struct nlattr *a[], u64 *attrsp, \fBbool\fP log, \fBbool\fP nz)"
.br
.ti -1c
.RI "static int \fBparse_flow_mask_nlattrs\fP (const struct nlattr *attr, const struct nlattr *a[], u64 *attrsp, \fBbool\fP log)"
.br
.ti -1c
.RI "static int \fBparse_flow_nlattrs\fP (const struct nlattr *attr, const struct nlattr *a[], u64 *attrsp, \fBbool\fP log)"
.br
.ti -1c
.RI "static int \fBgenev_tun_opt_from_nlattr\fP (const struct nlattr *a, struct \fBsw_flow_match\fP *match, \fBbool\fP is_mask, \fBbool\fP log)"
.br
.ti -1c
.RI "static int \fBvxlan_tun_opt_from_nlattr\fP (const struct nlattr *a, struct \fBsw_flow_match\fP *match, \fBbool\fP is_mask, \fBbool\fP log)"
.br
.ti -1c
.RI "static int \fBipv4_tun_from_nlattr\fP (const struct nlattr *attr, struct \fBsw_flow_match\fP *match, \fBbool\fP is_mask, \fBbool\fP log)"
.br
.ti -1c
.RI "static int \fBvxlan_opt_to_nlattr\fP (struct sk_buff *skb, const void *\fBtun_opts\fP, int swkey_tun_opts_len)"
.br
.ti -1c
.RI "static int \fB__ipv4_tun_to_nlattr\fP (struct sk_buff *skb, const struct \fBovs_key_ipv4_tunnel\fP *output, const void *\fBtun_opts\fP, int swkey_tun_opts_len)"
.br
.ti -1c
.RI "static int \fBipv4_tun_to_nlattr\fP (struct sk_buff *skb, const struct \fBovs_key_ipv4_tunnel\fP *output, const void *\fBtun_opts\fP, int swkey_tun_opts_len)"
.br
.ti -1c
.RI "int \fBovs_nla_put_egress_tunnel_key\fP (struct sk_buff *skb, const struct \fBovs_tunnel_info\fP *egress_tun_info)"
.br
.ti -1c
.RI "static int \fBmetadata_from_nlattrs\fP (struct \fBsw_flow_match\fP *match, u64 *attrs, const struct nlattr **a, \fBbool\fP is_mask, \fBbool\fP log)"
.br
.ti -1c
.RI "static int \fBovs_key_from_nlattrs\fP (struct \fBsw_flow_match\fP *match, u64 attrs, const struct nlattr **a, \fBbool\fP is_mask, \fBbool\fP log)"
.br
.ti -1c
.RI "static void \fBnlattr_set\fP (struct nlattr *attr, u8 val, const struct \fBovs_len_tbl\fP *tbl)"
.br
.ti -1c
.RI "static void \fBmask_set_nlattr\fP (struct nlattr *attr, u8 val)"
.br
.ti -1c
.RI "int \fBovs_nla_get_match\fP (struct \fBsw_flow_match\fP *match, const struct nlattr *nla_key, const struct nlattr *nla_mask, \fBbool\fP log)"
.br
.ti -1c
.RI "static size_t \fBget_ufid_len\fP (const struct nlattr *attr, \fBbool\fP log)"
.br
.ti -1c
.RI "\fBbool\fP \fBovs_nla_get_ufid\fP (struct \fBsw_flow_id\fP *sfid, const struct nlattr *attr, \fBbool\fP log)"
.br
.ti -1c
.RI "int \fBovs_nla_get_identifier\fP (struct \fBsw_flow_id\fP *sfid, const struct nlattr *ufid, const struct \fBsw_flow_key\fP *key, \fBbool\fP log)"
.br
.ti -1c
.RI "u32 \fBovs_nla_get_ufid_flags\fP (const struct nlattr *attr)"
.br
.ti -1c
.RI "int \fBovs_nla_get_flow_metadata\fP (const struct nlattr *attr, struct \fBsw_flow_key\fP *key, \fBbool\fP log)"
.br
.ti -1c
.RI "static int \fB__ovs_nla_put_key\fP (const struct \fBsw_flow_key\fP *swkey, const struct \fBsw_flow_key\fP *output, \fBbool\fP is_mask, struct sk_buff *skb)"
.br
.ti -1c
.RI "int \fBovs_nla_put_key\fP (const struct \fBsw_flow_key\fP *swkey, const struct \fBsw_flow_key\fP *output, int attr, \fBbool\fP is_mask, struct sk_buff *skb)"
.br
.ti -1c
.RI "int \fBovs_nla_put_identifier\fP (const struct \fBsw_flow\fP *flow, struct sk_buff *skb)"
.br
.ti -1c
.RI "int \fBovs_nla_put_masked_key\fP (const struct \fBsw_flow\fP *flow, struct sk_buff *skb)"
.br
.ti -1c
.RI "int \fBovs_nla_put_mask\fP (const struct \fBsw_flow\fP *flow, struct sk_buff *skb)"
.br
.ti -1c
.RI "static struct \fBsw_flow_actions\fP * \fBnla_alloc_flow_actions\fP (int size, \fBbool\fP log)"
.br
.ti -1c
.RI "static void \fBrcu_free_acts_callback\fP (struct rcu_head *rcu)"
.br
.ti -1c
.RI "void \fBovs_nla_free_flow_actions\fP (struct \fBsw_flow_actions\fP *sf_acts)"
.br
.ti -1c
.RI "static struct nlattr * \fBreserve_sfa_size\fP (struct \fBsw_flow_actions\fP **sfa, int attr_len, \fBbool\fP log)"
.br
.ti -1c
.RI "static struct nlattr * \fB__add_action\fP (struct \fBsw_flow_actions\fP **sfa, int attrtype, void *data, int len, \fBbool\fP log)"
.br
.ti -1c
.RI "static int \fBadd_action\fP (struct \fBsw_flow_actions\fP **sfa, int attrtype, void *data, int len, \fBbool\fP log)"
.br
.ti -1c
.RI "static int \fBadd_nested_action_start\fP (struct \fBsw_flow_actions\fP **sfa, int attrtype, \fBbool\fP log)"
.br
.ti -1c
.RI "static void \fBadd_nested_action_end\fP (struct \fBsw_flow_actions\fP *sfa, int st_offset)"
.br
.ti -1c
.RI "static int \fB__ovs_nla_copy_actions\fP (const struct nlattr *attr, const struct \fBsw_flow_key\fP *key, int depth, struct \fBsw_flow_actions\fP **sfa, __be16 eth_type, __be16 vlan_tci, \fBbool\fP log)"
.br
.ti -1c
.RI "static int \fBvalidate_and_copy_sample\fP (const struct nlattr *attr, const struct \fBsw_flow_key\fP *key, int depth, struct \fBsw_flow_actions\fP **sfa, __be16 eth_type, __be16 vlan_tci, \fBbool\fP log)"
.br
.ti -1c
.RI "void \fBovs_match_init\fP (struct \fBsw_flow_match\fP *match, struct \fBsw_flow_key\fP *key, struct \fBsw_flow_mask\fP *mask)"
.br
.ti -1c
.RI "static int \fBvalidate_geneve_opts\fP (struct \fBsw_flow_key\fP *key)"
.br
.ti -1c
.RI "static int \fBvalidate_and_copy_set_tun\fP (const struct nlattr *attr, struct \fBsw_flow_actions\fP **sfa, \fBbool\fP log)"
.br
.ti -1c
.RI "static \fBbool\fP \fBvalidate_masked\fP (u8 *data, int len)"
.br
.ti -1c
.RI "static int \fBvalidate_set\fP (const struct nlattr *a, const struct \fBsw_flow_key\fP *flow_key, struct \fBsw_flow_actions\fP **sfa, \fBbool\fP *skip_copy, __be16 eth_type, \fBbool\fP masked, \fBbool\fP log)"
.br
.ti -1c
.RI "static int \fBvalidate_userspace\fP (const struct nlattr *attr)"
.br
.ti -1c
.RI "static int \fBcopy_action\fP (const struct nlattr *from, struct \fBsw_flow_actions\fP **sfa, \fBbool\fP log)"
.br
.ti -1c
.RI "int \fBovs_nla_copy_actions\fP (const struct nlattr *attr, const struct \fBsw_flow_key\fP *key, struct \fBsw_flow_actions\fP **sfa, \fBbool\fP log)"
.br
.ti -1c
.RI "static int \fBsample_action_to_attr\fP (const struct nlattr *attr, struct sk_buff *skb)"
.br
.ti -1c
.RI "static int \fBset_action_to_attr\fP (const struct nlattr *a, struct sk_buff *skb)"
.br
.ti -1c
.RI "static int \fBmasked_set_action_to_set_action_attr\fP (const struct nlattr *a, struct sk_buff *skb)"
.br
.ti -1c
.RI "int \fBovs_nla_put_actions\fP (const struct nlattr *attr, int len, struct sk_buff *skb)"
.br
.in -1c
.SS "Variables"

.in +1c
.ti -1c
.RI "static const struct \fBovs_len_tbl\fP \fBovs_tunnel_key_lens\fP [\fBOVS_TUNNEL_KEY_ATTR_MAX\fP+1]"
.br
.ti -1c
.RI "static const struct \fBovs_len_tbl\fP \fBovs_key_lens\fP [\fBOVS_KEY_ATTR_MAX\fP+1]"
.br
.ti -1c
.RI "static const struct nla_policy \fBvxlan_opt_policy\fP [\fBOVS_VXLAN_EXT_MAX\fP+1]"
.br
.in -1c
.SH "Macro Definition Documentation"
.PP 
.SS "#define MAX_ACTIONS_BUFSIZE   (32 * 1024)"

.SS "#define OVS_ATTR_NESTED   -1"

.SS "#define pr_fmt(fmt)   KBUILD_MODNAME ': ' fmt"

.SS "#define SW_FLOW_KEY_MEMCPY(match, field, value_p, len, is_mask)"
\fBValue:\fP
.PP
.nf
SW_FLOW_KEY_MEMCPY_OFFSET(match, offsetof(struct sw_flow_key, field), \
                  value_p, len, is_mask)
.fi
.SS "#define SW_FLOW_KEY_MEMCPY_OFFSET(match, offset, value_p, len, is_mask)"
\fBValue:\fP
.PP
.nf
do {                                 \\
		update_range(match, offset, len, is_mask);            \
        if (is_mask)                            \
            memcpy((u8 *)&(match)->mask->key + offset, value_p, len);\
        else                                \
            memcpy((u8 *)(match)->key + offset, value_p, len);  \
    } while (0)
.fi
.SS "#define SW_FLOW_KEY_MEMSET_FIELD(match, field, value, is_mask)"
\fBValue:\fP
.PP
.nf
do {                                  \\
		update_range(match, offsetof(struct sw_flow_key, field),    \
                 sizeof((match)->key->field), is_mask);     \
        if (is_mask)                            \
            memset((u8 *)&(match)->mask->key\&.field, value,      \
                   sizeof((match)->mask->key\&.field));        \
        else                                \
            memset((u8 *)&(match)->key->field, value,           \
                   sizeof((match)->key->field));                \
    } while (0)
.fi
.SS "#define SW_FLOW_KEY_PUT(match, field, value, is_mask)"
\fBValue:\fP
.PP
.nf
do { \\
		update_range(match, offsetof(struct sw_flow_key, field),    \
                 sizeof((match)->key->field), is_mask);     \
        if (is_mask)                            \
            (match)->mask->key\&.field = value;            \
        else                                \
            (match)->key->field = value;                    \
    } while (0)
.fi
.SH "Function Documentation"
.PP 
.SS "static struct nlattr* __add_action (struct \fBsw_flow_actions\fP ** sfa, int attrtype, void * data, int len, \fBbool\fP log)\fC [static]\fP"

.PP
.nf
1604 {
1605     struct nlattr *a;
1606 
1607     a = reserve_sfa_size(sfa, nla_attr_size(len), log);
1608     if (IS_ERR(a))
1609         return a;
1610 
1611     a->nla_type = attrtype;
1612     a->nla_len = nla_attr_size(len);
1613 
1614     if (data)
1615         memcpy(nla_data(a), data, len);
1616     memset((unsigned char *) a + a->nla_len, 0, nla_padlen(len));
1617 
1618     return a;
1619 }
.fi
.SS "static int __ipv4_tun_to_nlattr (struct sk_buff * skb, const struct \fBovs_key_ipv4_tunnel\fP * output, const void * tun_opts, int swkey_tun_opts_len)\fC [static]\fP"

.PP
.nf
646 {
647     if (output->tun_flags & TUNNEL_KEY &&
648         nla_put_be64(skb, OVS_TUNNEL_KEY_ATTR_ID, output->tun_id))
649         return -EMSGSIZE;
650     if (output->ipv4_src &&
651         nla_put_be32(skb, OVS_TUNNEL_KEY_ATTR_IPV4_SRC, output->ipv4_src))
652         return -EMSGSIZE;
653     if (output->ipv4_dst &&
654         nla_put_be32(skb, OVS_TUNNEL_KEY_ATTR_IPV4_DST, output->ipv4_dst))
655         return -EMSGSIZE;
656     if (output->ipv4_tos &&
657         nla_put_u8(skb, OVS_TUNNEL_KEY_ATTR_TOS, output->ipv4_tos))
658         return -EMSGSIZE;
659     if (nla_put_u8(skb, OVS_TUNNEL_KEY_ATTR_TTL, output->ipv4_ttl))
660         return -EMSGSIZE;
661     if ((output->tun_flags & TUNNEL_DONT_FRAGMENT) &&
662         nla_put_flag(skb, OVS_TUNNEL_KEY_ATTR_DONT_FRAGMENT))
663         return -EMSGSIZE;
664     if ((output->tun_flags & TUNNEL_CSUM) &&
665         nla_put_flag(skb, OVS_TUNNEL_KEY_ATTR_CSUM))
666         return -EMSGSIZE;
667     if (output->tp_src &&
668         nla_put_be16(skb, OVS_TUNNEL_KEY_ATTR_TP_SRC, output->tp_src))
669         return -EMSGSIZE;
670     if (output->tp_dst &&
671         nla_put_be16(skb, OVS_TUNNEL_KEY_ATTR_TP_DST, output->tp_dst))
672         return -EMSGSIZE;
673     if ((output->tun_flags & TUNNEL_OAM) &&
674         nla_put_flag(skb, OVS_TUNNEL_KEY_ATTR_OAM))
675         return -EMSGSIZE;
676     if (tun_opts) {
677         if (output->tun_flags & TUNNEL_GENEVE_OPT &&
678             nla_put(skb, OVS_TUNNEL_KEY_ATTR_GENEVE_OPTS,
679                 swkey_tun_opts_len, tun_opts))
680             return -EMSGSIZE;
681                else if (output->tun_flags & TUNNEL_VXLAN_OPT &&
682             vxlan_opt_to_nlattr(skb, tun_opts, swkey_tun_opts_len))
683             return -EMSGSIZE;
684     }
685 
686     return 0;
687 }
.fi
.SS "static int __ovs_nla_copy_actions (const struct nlattr * attr, const struct \fBsw_flow_key\fP * key, int depth, struct \fBsw_flow_actions\fP ** sfa, __be16 eth_type, __be16 vlan_tci, \fBbool\fP log)\fC [static]\fP"

.PP
.nf
2027 {
2028     const struct nlattr *a;
2029     int rem, err;
2030 
2031     if (depth >= SAMPLE_ACTION_DEPTH)
2032         return -EOVERFLOW;
2033 
2034     nla_for_each_nested(a, attr, rem) {
2035         /* Expected argument lengths, (u32)-1 for variable length\&. */
2036         static const u32 action_lens[OVS_ACTION_ATTR_MAX + 1] = {
2037             [OVS_ACTION_ATTR_OUTPUT] = sizeof(u32),
2038             [OVS_ACTION_ATTR_RECIRC] = sizeof(u32),
2039             [OVS_ACTION_ATTR_USERSPACE] = (u32)-1,
2040             [OVS_ACTION_ATTR_PUSH_MPLS] = sizeof(struct ovs_action_push_mpls),
2041             [OVS_ACTION_ATTR_POP_MPLS] = sizeof(__be16),
2042             [OVS_ACTION_ATTR_PUSH_VLAN] = sizeof(struct ovs_action_push_vlan),
2043             [OVS_ACTION_ATTR_POP_VLAN] = 0,
2044             [OVS_ACTION_ATTR_SET] = (u32)-1,
2045             [OVS_ACTION_ATTR_SET_MASKED] = (u32)-1,
2046             [OVS_ACTION_ATTR_SAMPLE] = (u32)-1,
2047             [OVS_ACTION_ATTR_HASH] = sizeof(struct ovs_action_hash)
2048         };
2049         const struct ovs_action_push_vlan *vlan;
2050         int type = nla_type(a);
2051         bool skip_copy;
2052 
2053         if (type > OVS_ACTION_ATTR_MAX ||
2054             (action_lens[type] != nla_len(a) &&
2055              action_lens[type] != (u32)-1))
2056             return -EINVAL;
2057 
2058         skip_copy = false;
2059         switch (type) {
2060         case OVS_ACTION_ATTR_UNSPEC:
2061             return -EINVAL;
2062 
2063         case OVS_ACTION_ATTR_USERSPACE:
2064             err = validate_userspace(a);
2065             if (err)
2066                 return err;
2067             break;
2068 
2069         case OVS_ACTION_ATTR_OUTPUT:
2070             if (nla_get_u32(a) >= DP_MAX_PORTS)
2071                 return -EINVAL;
2072             break;
2073 
2074         case OVS_ACTION_ATTR_HASH: {
2075             const struct ovs_action_hash *act_hash = nla_data(a);
2076 
2077             switch (act_hash->hash_alg) {
2078             case OVS_HASH_ALG_L4:
2079                 break;
2080             default:
2081                 return  -EINVAL;
2082             }
2083 
2084             break;
2085         }
2086 
2087         case OVS_ACTION_ATTR_POP_VLAN:
2088             vlan_tci = htons(0);
2089             break;
2090 
2091         case OVS_ACTION_ATTR_PUSH_VLAN:
2092             vlan = nla_data(a);
2093             if (vlan->vlan_tpid != htons(ETH_P_8021Q))
2094                 return -EINVAL;
2095             if (!(vlan->vlan_tci & htons(VLAN_TAG_PRESENT)))
2096                 return -EINVAL;
2097             vlan_tci = vlan->vlan_tci;
2098             break;
2099 
2100         case OVS_ACTION_ATTR_RECIRC:
2101             break;
2102 
2103         case OVS_ACTION_ATTR_PUSH_MPLS: {
2104             const struct ovs_action_push_mpls *mpls = nla_data(a);
2105 
2106             if (!eth_p_mpls(mpls->mpls_ethertype))
2107                 return -EINVAL;
2108             /* Prohibit push MPLS other than to a white list
2109              * for packets that have a known tag order\&.
2110              */
2111             if (vlan_tci & htons(VLAN_TAG_PRESENT) ||
2112                 (eth_type != htons(ETH_P_IP) &&
2113                  eth_type != htons(ETH_P_IPV6) &&
2114                  eth_type != htons(ETH_P_ARP) &&
2115                  eth_type != htons(ETH_P_RARP) &&
2116                  !eth_p_mpls(eth_type)))
2117                 return -EINVAL;
2118             eth_type = mpls->mpls_ethertype;
2119             break;
2120         }
2121 
2122         case OVS_ACTION_ATTR_POP_MPLS:
2123             if (vlan_tci & htons(VLAN_TAG_PRESENT) ||
2124                 !eth_p_mpls(eth_type))
2125                 return -EINVAL;
2126 
2127             /* Disallow subsequent L2\&.5+ set and mpls_pop actions
2128              * as there is no check here to ensure that the new
2129              * eth_type is valid and thus set actions could
2130              * write off the end of the packet or otherwise
2131              * corrupt it\&.
2132              *
2133              * Support for these actions is planned using packet
2134              * recirculation\&.
2135              */
2136             eth_type = htons(0);
2137             break;
2138 
2139         case OVS_ACTION_ATTR_SET:
2140             err = validate_set(a, key, sfa,
2141                        &skip_copy, eth_type, false, log);
2142             if (err)
2143                 return err;
2144             break;
2145 
2146         case OVS_ACTION_ATTR_SET_MASKED:
2147             err = validate_set(a, key, sfa,
2148                        &skip_copy, eth_type, true, log);
2149             if (err)
2150                 return err;
2151             break;
2152 
2153         case OVS_ACTION_ATTR_SAMPLE:
2154             err = validate_and_copy_sample(a, key, depth, sfa,
2155                                eth_type, vlan_tci, log);
2156             if (err)
2157                 return err;
2158             skip_copy = true;
2159             break;
2160 
2161         default:
2162             OVS_NLERR(log, "Unknown Action type %d", type);
2163             return -EINVAL;
2164         }
2165         if (!skip_copy) {
2166             err = copy_action(a, sfa, log);
2167             if (err)
2168                 return err;
2169         }
2170     }
2171 
2172     if (rem > 0)
2173         return -EINVAL;
2174 
2175     return 0;
2176 }
.fi
.SS "static int __ovs_nla_put_key (const struct \fBsw_flow_key\fP * swkey, const struct \fBsw_flow_key\fP * output, \fBbool\fP is_mask, struct sk_buff * skb)\fC [static]\fP"

.PP
.nf
1277 {
1278     struct ovs_key_ethernet *eth_key;
1279     struct nlattr *nla, *encap;
1280 
1281     if (nla_put_u32(skb, OVS_KEY_ATTR_RECIRC_ID, output->recirc_id))
1282         goto nla_put_failure;
1283 
1284     if (nla_put_u32(skb, OVS_KEY_ATTR_DP_HASH, output->ovs_flow_hash))
1285         goto nla_put_failure;
1286 
1287     if (nla_put_u32(skb, OVS_KEY_ATTR_PRIORITY, output->phy\&.priority))
1288         goto nla_put_failure;
1289 
1290     if ((swkey->tun_key\&.ipv4_dst || is_mask)) {
1291         const void *opts = NULL;
1292 
1293         if (output->tun_key\&.tun_flags & TUNNEL_OPTIONS_PRESENT)
1294             opts = TUN_METADATA_OPTS(output, swkey->tun_opts_len);
1295 
1296         if (ipv4_tun_to_nlattr(skb, &output->tun_key, opts,
1297                        swkey->tun_opts_len))
1298             goto nla_put_failure;
1299     }
1300 
1301     if (swkey->phy\&.in_port == DP_MAX_PORTS) {
1302         if (is_mask && (output->phy\&.in_port == 0xffff))
1303             if (nla_put_u32(skb, OVS_KEY_ATTR_IN_PORT, 0xffffffff))
1304                 goto nla_put_failure;
1305     } else {
1306         u16 upper_u16;
1307         upper_u16 = !is_mask ? 0 : 0xffff;
1308 
1309         if (nla_put_u32(skb, OVS_KEY_ATTR_IN_PORT,
1310                 (upper_u16 << 16) | output->phy\&.in_port))
1311             goto nla_put_failure;
1312     }
1313 
1314     if (nla_put_u32(skb, OVS_KEY_ATTR_SKB_MARK, output->phy\&.skb_mark))
1315         goto nla_put_failure;
1316 
1317     nla = nla_reserve(skb, OVS_KEY_ATTR_ETHERNET, sizeof(*eth_key));
1318     if (!nla)
1319         goto nla_put_failure;
1320 
1321     eth_key = nla_data(nla);
1322     ether_addr_copy(eth_key->eth_src, output->eth\&.src);
1323     ether_addr_copy(eth_key->eth_dst, output->eth\&.dst);
1324 
1325     if (swkey->eth\&.tci || swkey->eth\&.type == htons(ETH_P_8021Q)) {
1326         __be16 eth_type;
1327         eth_type = !is_mask ? htons(ETH_P_8021Q) : htons(0xffff);
1328         if (nla_put_be16(skb, OVS_KEY_ATTR_ETHERTYPE, eth_type) ||
1329             nla_put_be16(skb, OVS_KEY_ATTR_VLAN, output->eth\&.tci))
1330             goto nla_put_failure;
1331         encap = nla_nest_start(skb, OVS_KEY_ATTR_ENCAP);
1332         if (!swkey->eth\&.tci)
1333             goto unencap;
1334     } else
1335         encap = NULL;
1336 
1337     if (swkey->eth\&.type == htons(ETH_P_802_2)) {
1338         /*
1339          * Ethertype 802\&.2 is represented in the netlink with omitted
1340          * OVS_KEY_ATTR_ETHERTYPE in the flow key attribute, and
1341          * 0xffff in the mask attribute\&.  Ethertype can also
1342          * be wildcarded\&.
1343          */
1344         if (is_mask && output->eth\&.type)
1345             if (nla_put_be16(skb, OVS_KEY_ATTR_ETHERTYPE,
1346                         output->eth\&.type))
1347                 goto nla_put_failure;
1348         goto unencap;
1349     }
1350 
1351     if (nla_put_be16(skb, OVS_KEY_ATTR_ETHERTYPE, output->eth\&.type))
1352         goto nla_put_failure;
1353 
1354     if (swkey->eth\&.type == htons(ETH_P_IP)) {
1355         struct ovs_key_ipv4 *ipv4_key;
1356 
1357         nla = nla_reserve(skb, OVS_KEY_ATTR_IPV4, sizeof(*ipv4_key));
1358         if (!nla)
1359             goto nla_put_failure;
1360         ipv4_key = nla_data(nla);
1361         ipv4_key->ipv4_src = output->ipv4\&.addr\&.src;
1362         ipv4_key->ipv4_dst = output->ipv4\&.addr\&.dst;
1363         ipv4_key->ipv4_proto = output->ip\&.proto;
1364         ipv4_key->ipv4_tos = output->ip\&.tos;
1365         ipv4_key->ipv4_ttl = output->ip\&.ttl;
1366         ipv4_key->ipv4_frag = output->ip\&.frag;
1367     } else if (swkey->eth\&.type == htons(ETH_P_IPV6)) {
1368         struct ovs_key_ipv6 *ipv6_key;
1369 
1370         nla = nla_reserve(skb, OVS_KEY_ATTR_IPV6, sizeof(*ipv6_key));
1371         if (!nla)
1372             goto nla_put_failure;
1373         ipv6_key = nla_data(nla);
1374         memcpy(ipv6_key->ipv6_src, &output->ipv6\&.addr\&.src,
1375                 sizeof(ipv6_key->ipv6_src));
1376         memcpy(ipv6_key->ipv6_dst, &output->ipv6\&.addr\&.dst,
1377                 sizeof(ipv6_key->ipv6_dst));
1378         ipv6_key->ipv6_label = output->ipv6\&.label;
1379         ipv6_key->ipv6_proto = output->ip\&.proto;
1380         ipv6_key->ipv6_tclass = output->ip\&.tos;
1381         ipv6_key->ipv6_hlimit = output->ip\&.ttl;
1382         ipv6_key->ipv6_frag = output->ip\&.frag;
1383     } else if (swkey->eth\&.type == htons(ETH_P_ARP) ||
1384            swkey->eth\&.type == htons(ETH_P_RARP)) {
1385         struct ovs_key_arp *arp_key;
1386 
1387         nla = nla_reserve(skb, OVS_KEY_ATTR_ARP, sizeof(*arp_key));
1388         if (!nla)
1389             goto nla_put_failure;
1390         arp_key = nla_data(nla);
1391         memset(arp_key, 0, sizeof(struct ovs_key_arp));
1392         arp_key->arp_sip = output->ipv4\&.addr\&.src;
1393         arp_key->arp_tip = output->ipv4\&.addr\&.dst;
1394         arp_key->arp_op = htons(output->ip\&.proto);
1395         ether_addr_copy(arp_key->arp_sha, output->ipv4\&.arp\&.sha);
1396         ether_addr_copy(arp_key->arp_tha, output->ipv4\&.arp\&.tha);
1397     } else if (eth_p_mpls(swkey->eth\&.type)) {
1398         struct ovs_key_mpls *mpls_key;
1399 
1400         nla = nla_reserve(skb, OVS_KEY_ATTR_MPLS, sizeof(*mpls_key));
1401         if (!nla)
1402             goto nla_put_failure;
1403         mpls_key = nla_data(nla);
1404         mpls_key->mpls_lse = output->mpls\&.top_lse;
1405     }
1406 
1407     if ((swkey->eth\&.type == htons(ETH_P_IP) ||
1408          swkey->eth\&.type == htons(ETH_P_IPV6)) &&
1409          swkey->ip\&.frag != OVS_FRAG_TYPE_LATER) {
1410 
1411         if (swkey->ip\&.proto == IPPROTO_TCP) {
1412             struct ovs_key_tcp *tcp_key;
1413 
1414             nla = nla_reserve(skb, OVS_KEY_ATTR_TCP, sizeof(*tcp_key));
1415             if (!nla)
1416                 goto nla_put_failure;
1417             tcp_key = nla_data(nla);
1418             tcp_key->tcp_src = output->tp\&.src;
1419             tcp_key->tcp_dst = output->tp\&.dst;
1420             if (nla_put_be16(skb, OVS_KEY_ATTR_TCP_FLAGS,
1421                      output->tp\&.flags))
1422                 goto nla_put_failure;
1423         } else if (swkey->ip\&.proto == IPPROTO_UDP) {
1424             struct ovs_key_udp *udp_key;
1425 
1426             nla = nla_reserve(skb, OVS_KEY_ATTR_UDP, sizeof(*udp_key));
1427             if (!nla)
1428                 goto nla_put_failure;
1429             udp_key = nla_data(nla);
1430             udp_key->udp_src = output->tp\&.src;
1431             udp_key->udp_dst = output->tp\&.dst;
1432         } else if (swkey->ip\&.proto == IPPROTO_SCTP) {
1433             struct ovs_key_sctp *sctp_key;
1434 
1435             nla = nla_reserve(skb, OVS_KEY_ATTR_SCTP, sizeof(*sctp_key));
1436             if (!nla)
1437                 goto nla_put_failure;
1438             sctp_key = nla_data(nla);
1439             sctp_key->sctp_src = output->tp\&.src;
1440             sctp_key->sctp_dst = output->tp\&.dst;
1441         } else if (swkey->eth\&.type == htons(ETH_P_IP) &&
1442                swkey->ip\&.proto == IPPROTO_ICMP) {
1443             struct ovs_key_icmp *icmp_key;
1444 
1445             nla = nla_reserve(skb, OVS_KEY_ATTR_ICMP, sizeof(*icmp_key));
1446             if (!nla)
1447                 goto nla_put_failure;
1448             icmp_key = nla_data(nla);
1449             icmp_key->icmp_type = ntohs(output->tp\&.src);
1450             icmp_key->icmp_code = ntohs(output->tp\&.dst);
1451         } else if (swkey->eth\&.type == htons(ETH_P_IPV6) &&
1452                swkey->ip\&.proto == IPPROTO_ICMPV6) {
1453             struct ovs_key_icmpv6 *icmpv6_key;
1454 
1455             nla = nla_reserve(skb, OVS_KEY_ATTR_ICMPV6,
1456                         sizeof(*icmpv6_key));
1457             if (!nla)
1458                 goto nla_put_failure;
1459             icmpv6_key = nla_data(nla);
1460             icmpv6_key->icmpv6_type = ntohs(output->tp\&.src);
1461             icmpv6_key->icmpv6_code = ntohs(output->tp\&.dst);
1462 
1463             if (icmpv6_key->icmpv6_type == NDISC_NEIGHBOUR_SOLICITATION ||
1464                 icmpv6_key->icmpv6_type == NDISC_NEIGHBOUR_ADVERTISEMENT) {
1465                 struct ovs_key_nd *nd_key;
1466 
1467                 nla = nla_reserve(skb, OVS_KEY_ATTR_ND, sizeof(*nd_key));
1468                 if (!nla)
1469                     goto nla_put_failure;
1470                 nd_key = nla_data(nla);
1471                 memcpy(nd_key->nd_target, &output->ipv6\&.nd\&.target,
1472                             sizeof(nd_key->nd_target));
1473                 ether_addr_copy(nd_key->nd_sll, output->ipv6\&.nd\&.sll);
1474                 ether_addr_copy(nd_key->nd_tll, output->ipv6\&.nd\&.tll);
1475             }
1476         }
1477     }
1478 
1479 unencap:
1480     if (encap)
1481         nla_nest_end(skb, encap);
1482 
1483     return 0;
1484 
1485 nla_put_failure:
1486     return -EMSGSIZE;
1487 }
.fi
.SS "static int __parse_flow_nlattrs (const struct nlattr * attr, const struct nlattr * a[], u64 * attrsp, \fBbool\fP log, \fBbool\fP nz)\fC [static]\fP"

.PP
.nf
361 {
362     const struct nlattr *nla;
363     u64 attrs;
364     int rem;
365 
366     attrs = *attrsp;
367     nla_for_each_nested(nla, attr, rem) {
368         u16 type = nla_type(nla);
369         int expected_len;
370 
371         if (type > OVS_KEY_ATTR_MAX) {
372             OVS_NLERR(log, "Key type %d is out of range max %d",
373                   type, OVS_KEY_ATTR_MAX);
374             return -EINVAL;
375         }
376 
377         if (attrs & (1ULL << type)) {
378             OVS_NLERR(log, "Duplicate key (type %d)\&.", type);
379             return -EINVAL;
380         }
381 
382         expected_len = ovs_key_lens[type]\&.len;
383         if (nla_len(nla) != expected_len && expected_len != OVS_ATTR_NESTED) {
384             OVS_NLERR(log, "Key %d has unexpected len %d expected %d",
385                   type, nla_len(nla), expected_len);
386             return -EINVAL;
387         }
388 
389         if (!nz || !is_all_zero(nla_data(nla), expected_len)) {
390             attrs |= 1ULL << type;
391             a[type] = nla;
392         }
393     }
394     if (rem) {
395         OVS_NLERR(log, "Message has %d unknown bytes\&.", rem);
396         return -EINVAL;
397     }
398 
399     *attrsp = attrs;
400     return 0;
401 }
.fi
.SS "static int add_action (struct \fBsw_flow_actions\fP ** sfa, int attrtype, void * data, int len, \fBbool\fP log)\fC [static]\fP"

.PP
.nf
1623 {
1624     struct nlattr *a;
1625 
1626     a = __add_action(sfa, attrtype, data, len, log);
1627     if (IS_ERR(a))
1628         return PTR_ERR(a);
1629 
1630     return 0;
1631 }
.fi
.SS "static void add_nested_action_end (struct \fBsw_flow_actions\fP * sfa, int st_offset)\fC [inline]\fP, \fC [static]\fP"

.PP
.nf
1648 {
1649     struct nlattr *a = (struct nlattr *) ((unsigned char *)sfa->actions +
1650                                    st_offset);
1651 
1652     a->nla_len = sfa->actions_len - st_offset;
1653 }
.fi
.SS "static int add_nested_action_start (struct \fBsw_flow_actions\fP ** sfa, int attrtype, \fBbool\fP log)\fC [inline]\fP, \fC [static]\fP"

.PP
.nf
1635 {
1636     int used = (*sfa)->actions_len;
1637     int err;
1638 
1639     err = add_action(sfa, attrtype, NULL, 0, log);
1640     if (err)
1641         return err;
1642 
1643     return used;
1644 }
.fi
.SS "static int copy_action (const struct nlattr * from, struct \fBsw_flow_actions\fP ** sfa, \fBbool\fP log)\fC [static]\fP"

.PP
.nf
2011 {
2012     int totlen = NLA_ALIGN(from->nla_len);
2013     struct nlattr *to;
2014 
2015     to = reserve_sfa_size(sfa, from->nla_len, log);
2016     if (IS_ERR(to))
2017         return PTR_ERR(to);
2018 
2019     memcpy(to, from, totlen);
2020     return 0;
2021 }
.fi
.SS "static int genev_tun_opt_from_nlattr (const struct nlattr * a, struct \fBsw_flow_match\fP * match, \fBbool\fP is_mask, \fBbool\fP log)\fC [static]\fP"

.PP
.nf
420 {
421     unsigned long opt_key_offset;
422 
423     if (nla_len(a) > sizeof(match->key->tun_opts)) {
424         OVS_NLERR(log, "Geneve option length err (len %d, max %zu)\&.",
425               nla_len(a), sizeof(match->key->tun_opts));
426         return -EINVAL;
427     }
428 
429     if (nla_len(a) % 4 != 0) {
430         OVS_NLERR(log, "Geneve opt len %d is not a multiple of 4\&.",
431               nla_len(a));
432         return -EINVAL;
433     }
434 
435     /* We need to record the length of the options passed
436      * down, otherwise packets with the same format but
437      * additional options will be silently matched\&.
438      */
439     if (!is_mask) {
440         SW_FLOW_KEY_PUT(match, tun_opts_len, nla_len(a),
441                 false);
442     } else {
443         /* This is somewhat unusual because it looks at
444          * both the key and mask while parsing the
445          * attributes (and by extension assumes the key
446          * is parsed first)\&. Normally, we would verify
447          * that each is the correct length and that the
448          * attributes line up in the validate function\&.
449          * However, that is difficult because this is
450          * variable length and we won't have the
451          * information later\&.
452          */
453         if (match->key->tun_opts_len != nla_len(a)) {
454             OVS_NLERR(log, "Geneve option len %d != mask len %d",
455                   match->key->tun_opts_len, nla_len(a));
456             return -EINVAL;
457         }
458 
459         SW_FLOW_KEY_PUT(match, tun_opts_len, 0xff, true);
460     }
461 
462     opt_key_offset = TUN_METADATA_OFFSET(nla_len(a));
463     SW_FLOW_KEY_MEMCPY_OFFSET(match, opt_key_offset, nla_data(a),
464                   nla_len(a), is_mask);
465     return 0;
466 }
.fi
.SS "static size_t get_ufid_len (const struct nlattr * attr, \fBbool\fP log)\fC [static]\fP"

.PP
.nf
1185 {
1186     size_t len;
1187 
1188     if (!attr)
1189         return 0;
1190 
1191     len = nla_len(attr);
1192     if (len < 1 || len > MAX_UFID_LENGTH) {
1193         OVS_NLERR(log, "ufid size %u bytes exceeds the range (1, %d)",
1194               nla_len(attr), MAX_UFID_LENGTH);
1195         return 0;
1196     }
1197 
1198     return len;
1199 }
.fi
.SS "static int ipv4_tun_from_nlattr (const struct nlattr * attr, struct \fBsw_flow_match\fP * match, \fBbool\fP is_mask, \fBbool\fP log)\fC [static]\fP"

.PP
.nf
506 {
507     struct nlattr *a;
508     int rem;
509     bool ttl = false;
510     __be16 tun_flags = 0;
511     int opts_type = 0;
512 
513     nla_for_each_nested(a, attr, rem) {
514         int type = nla_type(a);
515         int err;
516 
517         if (type > OVS_TUNNEL_KEY_ATTR_MAX) {
518             OVS_NLERR(log, "Tunnel attr %d out of range max %d",
519                   type, OVS_TUNNEL_KEY_ATTR_MAX);
520             return -EINVAL;
521         }
522 
523         if (ovs_tunnel_key_lens[type]\&.len != nla_len(a) &&
524            ovs_tunnel_key_lens[type]\&.len != OVS_ATTR_NESTED) {
525             OVS_NLERR(log, "Tunnel attr %d has unexpected len %d expected %d",
526                   type, nla_len(a), ovs_tunnel_key_lens[type]\&.len);
527             return -EINVAL;
528         }
529 
530         switch (type) {
531         case OVS_TUNNEL_KEY_ATTR_ID:
532             SW_FLOW_KEY_PUT(match, tun_key\&.tun_id,
533                     nla_get_be64(a), is_mask);
534             tun_flags |= TUNNEL_KEY;
535             break;
536         case OVS_TUNNEL_KEY_ATTR_IPV4_SRC:
537             SW_FLOW_KEY_PUT(match, tun_key\&.ipv4_src,
538                     nla_get_be32(a), is_mask);
539             break;
540         case OVS_TUNNEL_KEY_ATTR_IPV4_DST:
541             SW_FLOW_KEY_PUT(match, tun_key\&.ipv4_dst,
542                     nla_get_be32(a), is_mask);
543             break;
544         case OVS_TUNNEL_KEY_ATTR_TOS:
545             SW_FLOW_KEY_PUT(match, tun_key\&.ipv4_tos,
546                     nla_get_u8(a), is_mask);
547             break;
548         case OVS_TUNNEL_KEY_ATTR_TTL:
549             SW_FLOW_KEY_PUT(match, tun_key\&.ipv4_ttl,
550                     nla_get_u8(a), is_mask);
551             ttl = true;
552             break;
553         case OVS_TUNNEL_KEY_ATTR_DONT_FRAGMENT:
554             tun_flags |= TUNNEL_DONT_FRAGMENT;
555             break;
556         case OVS_TUNNEL_KEY_ATTR_CSUM:
557             tun_flags |= TUNNEL_CSUM;
558             break;
559         case OVS_TUNNEL_KEY_ATTR_TP_SRC:
560             SW_FLOW_KEY_PUT(match, tun_key\&.tp_src,
561                     nla_get_be16(a), is_mask);
562             break;
563         case OVS_TUNNEL_KEY_ATTR_TP_DST:
564             SW_FLOW_KEY_PUT(match, tun_key\&.tp_dst,
565                     nla_get_be16(a), is_mask);
566             break;
567         case OVS_TUNNEL_KEY_ATTR_OAM:
568             tun_flags |= TUNNEL_OAM;
569             break;
570         case OVS_TUNNEL_KEY_ATTR_GENEVE_OPTS:
571             if (opts_type) {
572                 OVS_NLERR(log, "Multiple metadata blocks provided");
573                 return -EINVAL;
574             }
575 
576             err = genev_tun_opt_from_nlattr(a, match, is_mask, log);
577             if (err)
578                 return err;
579 
580             tun_flags |= TUNNEL_GENEVE_OPT;
581             opts_type = type;
582             break;
583         case OVS_TUNNEL_KEY_ATTR_VXLAN_OPTS:
584             if (opts_type) {
585                 OVS_NLERR(log, "Multiple metadata blocks provided");
586                 return -EINVAL;
587             }
588 
589             err = vxlan_tun_opt_from_nlattr(a, match, is_mask, log);
590             if (err)
591                 return err;
592 
593             tun_flags |= TUNNEL_VXLAN_OPT;
594             opts_type = type;
595             break;
596         default:
597             OVS_NLERR(log, "Unknown IPv4 tunnel attribute %d",
598                   type);
599             return -EINVAL;
600         }
601     }
602 
603     SW_FLOW_KEY_PUT(match, tun_key\&.tun_flags, tun_flags, is_mask);
604 
605     if (rem > 0) {
606         OVS_NLERR(log, "IPv4 tunnel attribute has %d unknown bytes\&.",
607               rem);
608         return -EINVAL;
609     }
610 
611     if (!is_mask) {
612         if (!match->key->tun_key\&.ipv4_dst) {
613             OVS_NLERR(log, "IPv4 tunnel dst address is zero");
614             return -EINVAL;
615         }
616 
617         if (!ttl) {
618             OVS_NLERR(log, "IPv4 tunnel TTL not specified\&.");
619             return -EINVAL;
620         }
621     }
622 
623     return opts_type;
624 }
.fi
.SS "static int ipv4_tun_to_nlattr (struct sk_buff * skb, const struct \fBovs_key_ipv4_tunnel\fP * output, const void * tun_opts, int swkey_tun_opts_len)\fC [static]\fP"

.PP
.nf
692 {
693     struct nlattr *nla;
694     int err;
695 
696     nla = nla_nest_start(skb, OVS_KEY_ATTR_TUNNEL);
697     if (!nla)
698         return -EMSGSIZE;
699 
700     err = __ipv4_tun_to_nlattr(skb, output, tun_opts, swkey_tun_opts_len);
701     if (err)
702         return err;
703 
704     nla_nest_end(skb, nla);
705     return 0;
706 }
.fi
.SS "static \fBbool\fP is_all_zero (const u8 * fp, size_t size)\fC [static]\fP"

.PP
.nf
345 {
346     int i;
347 
348     if (!fp)
349         return false;
350 
351     for (i = 0; i < size; i++)
352         if (fp[i])
353             return false;
354 
355     return true;
356 }
.fi
.SS "static void mask_set_nlattr (struct nlattr * attr, u8 val)\fC [static]\fP"

.PP
.nf
1022 {
1023     nlattr_set(attr, val, ovs_key_lens);
1024 }
.fi
.SS "static int masked_set_action_to_set_action_attr (const struct nlattr * a, struct sk_buff * skb)\fC [static]\fP"

.PP
.nf
2268 {
2269     const struct nlattr *ovs_key = nla_data(a);
2270     size_t key_len = nla_len(ovs_key) / 2;
2271 
2272     /* Revert the conversion we did from a non-masked set action to
2273      * masked set action\&.
2274      */
2275     if (nla_put(skb, OVS_ACTION_ATTR_SET, nla_len(a) - key_len, ovs_key))
2276         return -EMSGSIZE;
2277 
2278     return 0;
2279 }
.fi
.SS "static \fBbool\fP match_validate (const struct \fBsw_flow_match\fP * match, u64 key_attrs, u64 mask_attrs, \fBbool\fP log)\fC [static]\fP"

.PP
.nf
123 {
124     u64 key_expected = 1ULL << OVS_KEY_ATTR_ETHERNET;
125     u64 mask_allowed = key_attrs;  /* At most allow all key attributes */
126 
127     /* The following mask attributes allowed only if they
128      * pass the validation tests\&.
129      */
130     mask_allowed &= ~((1ULL << OVS_KEY_ATTR_IPV4)
131             | (1ULL << OVS_KEY_ATTR_IPV6)
132             | (1ULL << OVS_KEY_ATTR_TCP)
133             | (1ULL << OVS_KEY_ATTR_TCP_FLAGS)
134             | (1ULL << OVS_KEY_ATTR_UDP)
135             | (1ULL << OVS_KEY_ATTR_SCTP)
136             | (1ULL << OVS_KEY_ATTR_ICMP)
137             | (1ULL << OVS_KEY_ATTR_ICMPV6)
138             | (1ULL << OVS_KEY_ATTR_ARP)
139             | (1ULL << OVS_KEY_ATTR_ND)
140             | (1ULL << OVS_KEY_ATTR_MPLS));
141 
142     /* Always allowed mask fields\&. */
143     mask_allowed |= ((1ULL << OVS_KEY_ATTR_TUNNEL)
144                | (1ULL << OVS_KEY_ATTR_IN_PORT)
145                | (1ULL << OVS_KEY_ATTR_ETHERTYPE));
146 
147     /* Check key attributes\&. */
148     if (match->key->eth\&.type == htons(ETH_P_ARP)
149             || match->key->eth\&.type == htons(ETH_P_RARP)) {
150         key_expected |= 1ULL << OVS_KEY_ATTR_ARP;
151         if (match->mask && (match->mask->key\&.eth\&.type == htons(0xffff)))
152             mask_allowed |= 1ULL << OVS_KEY_ATTR_ARP;
153     }
154 
155     if (eth_p_mpls(match->key->eth\&.type)) {
156         key_expected |= 1ULL << OVS_KEY_ATTR_MPLS;
157         if (match->mask && (match->mask->key\&.eth\&.type == htons(0xffff)))
158             mask_allowed |= 1ULL << OVS_KEY_ATTR_MPLS;
159     }
160 
161     if (match->key->eth\&.type == htons(ETH_P_IP)) {
162         key_expected |= 1ULL << OVS_KEY_ATTR_IPV4;
163         if (match->mask && (match->mask->key\&.eth\&.type == htons(0xffff)))
164             mask_allowed |= 1ULL << OVS_KEY_ATTR_IPV4;
165 
166         if (match->key->ip\&.frag != OVS_FRAG_TYPE_LATER) {
167             if (match->key->ip\&.proto == IPPROTO_UDP) {
168                 key_expected |= 1ULL << OVS_KEY_ATTR_UDP;
169                 if (match->mask && (match->mask->key\&.ip\&.proto == 0xff))
170                     mask_allowed |= 1ULL << OVS_KEY_ATTR_UDP;
171             }
172 
173             if (match->key->ip\&.proto == IPPROTO_SCTP) {
174                 key_expected |= 1ULL << OVS_KEY_ATTR_SCTP;
175                 if (match->mask && (match->mask->key\&.ip\&.proto == 0xff))
176                     mask_allowed |= 1ULL << OVS_KEY_ATTR_SCTP;
177             }
178 
179             if (match->key->ip\&.proto == IPPROTO_TCP) {
180                 key_expected |= 1ULL << OVS_KEY_ATTR_TCP;
181                 key_expected |= 1ULL << OVS_KEY_ATTR_TCP_FLAGS;
182                 if (match->mask && (match->mask->key\&.ip\&.proto == 0xff)) {
183                     mask_allowed |= 1ULL << OVS_KEY_ATTR_TCP;
184                     mask_allowed |= 1ULL << OVS_KEY_ATTR_TCP_FLAGS;
185                 }
186             }
187 
188             if (match->key->ip\&.proto == IPPROTO_ICMP) {
189                 key_expected |= 1ULL << OVS_KEY_ATTR_ICMP;
190                 if (match->mask && (match->mask->key\&.ip\&.proto == 0xff))
191                     mask_allowed |= 1ULL << OVS_KEY_ATTR_ICMP;
192             }
193         }
194     }
195 
196     if (match->key->eth\&.type == htons(ETH_P_IPV6)) {
197         key_expected |= 1ULL << OVS_KEY_ATTR_IPV6;
198         if (match->mask && (match->mask->key\&.eth\&.type == htons(0xffff)))
199             mask_allowed |= 1ULL << OVS_KEY_ATTR_IPV6;
200 
201         if (match->key->ip\&.frag != OVS_FRAG_TYPE_LATER) {
202             if (match->key->ip\&.proto == IPPROTO_UDP) {
203                 key_expected |= 1ULL << OVS_KEY_ATTR_UDP;
204                 if (match->mask && (match->mask->key\&.ip\&.proto == 0xff))
205                     mask_allowed |= 1ULL << OVS_KEY_ATTR_UDP;
206             }
207 
208             if (match->key->ip\&.proto == IPPROTO_SCTP) {
209                 key_expected |= 1ULL << OVS_KEY_ATTR_SCTP;
210                 if (match->mask && (match->mask->key\&.ip\&.proto == 0xff))
211                     mask_allowed |= 1ULL << OVS_KEY_ATTR_SCTP;
212             }
213 
214             if (match->key->ip\&.proto == IPPROTO_TCP) {
215                 key_expected |= 1ULL << OVS_KEY_ATTR_TCP;
216                 key_expected |= 1ULL << OVS_KEY_ATTR_TCP_FLAGS;
217                 if (match->mask && (match->mask->key\&.ip\&.proto == 0xff)) {
218                     mask_allowed |= 1ULL << OVS_KEY_ATTR_TCP;
219                     mask_allowed |= 1ULL << OVS_KEY_ATTR_TCP_FLAGS;
220                 }
221             }
222 
223             if (match->key->ip\&.proto == IPPROTO_ICMPV6) {
224                 key_expected |= 1ULL << OVS_KEY_ATTR_ICMPV6;
225                 if (match->mask && (match->mask->key\&.ip\&.proto == 0xff))
226                     mask_allowed |= 1ULL << OVS_KEY_ATTR_ICMPV6;
227 
228                 if (match->key->tp\&.src ==
229                         htons(NDISC_NEIGHBOUR_SOLICITATION) ||
230                     match->key->tp\&.src == htons(NDISC_NEIGHBOUR_ADVERTISEMENT)) {
231                     key_expected |= 1ULL << OVS_KEY_ATTR_ND;
232                     if (match->mask && (match->mask->key\&.tp\&.src == htons(0xff)))
233                         mask_allowed |= 1ULL << OVS_KEY_ATTR_ND;
234                 }
235             }
236         }
237     }
238 
239     if ((key_attrs & key_expected) != key_expected) {
240         /* Key attributes check failed\&. */
241         OVS_NLERR(log, "Missing key (keys=%llx, expected=%llx)",
242               (unsigned long long)key_attrs,
243               (unsigned long long)key_expected);
244         return false;
245     }
246 
247     if ((mask_attrs & mask_allowed) != mask_attrs) {
248         /* Mask attributes check failed\&. */
249         OVS_NLERR(log, "Unexpected mask (mask=%llx, allowed=%llx)",
250               (unsigned long long)mask_attrs,
251               (unsigned long long)mask_allowed);
252         return false;
253     }
254 
255     return true;
256 }
.fi
.SS "static int metadata_from_nlattrs (struct \fBsw_flow_match\fP * match, u64 * attrs, const struct nlattr ** a, \fBbool\fP is_mask, \fBbool\fP log)\fC [static]\fP"

.PP
.nf
719 {
720     if (*attrs & (1ULL << OVS_KEY_ATTR_DP_HASH)) {
721         u32 hash_val = nla_get_u32(a[OVS_KEY_ATTR_DP_HASH]);
722 
723         SW_FLOW_KEY_PUT(match, ovs_flow_hash, hash_val, is_mask);
724         *attrs &= ~(1ULL << OVS_KEY_ATTR_DP_HASH);
725     }
726 
727     if (*attrs & (1ULL << OVS_KEY_ATTR_RECIRC_ID)) {
728         u32 recirc_id = nla_get_u32(a[OVS_KEY_ATTR_RECIRC_ID]);
729 
730         SW_FLOW_KEY_PUT(match, recirc_id, recirc_id, is_mask);
731         *attrs &= ~(1ULL << OVS_KEY_ATTR_RECIRC_ID);
732     }
733 
734     if (*attrs & (1ULL << OVS_KEY_ATTR_PRIORITY)) {
735         SW_FLOW_KEY_PUT(match, phy\&.priority,
736               nla_get_u32(a[OVS_KEY_ATTR_PRIORITY]), is_mask);
737         *attrs &= ~(1ULL << OVS_KEY_ATTR_PRIORITY);
738     }
739 
740     if (*attrs & (1ULL << OVS_KEY_ATTR_IN_PORT)) {
741         u32 in_port = nla_get_u32(a[OVS_KEY_ATTR_IN_PORT]);
742 
743         if (is_mask) {
744             in_port = 0xffffffff; /* Always exact match in_port\&. */
745         } else if (in_port >= DP_MAX_PORTS) {
746             OVS_NLERR(log, "Port %d exceeds max allowable %d",
747                   in_port, DP_MAX_PORTS);
748             return -EINVAL;
749         }
750 
751         SW_FLOW_KEY_PUT(match, phy\&.in_port, in_port, is_mask);
752         *attrs &= ~(1ULL << OVS_KEY_ATTR_IN_PORT);
753     } else if (!is_mask) {
754         SW_FLOW_KEY_PUT(match, phy\&.in_port, DP_MAX_PORTS, is_mask);
755     }
756 
757     if (*attrs & (1ULL << OVS_KEY_ATTR_SKB_MARK)) {
758         uint32_t mark = nla_get_u32(a[OVS_KEY_ATTR_SKB_MARK]);
759 
760         SW_FLOW_KEY_PUT(match, phy\&.skb_mark, mark, is_mask);
761         *attrs &= ~(1ULL << OVS_KEY_ATTR_SKB_MARK);
762     }
763     if (*attrs & (1ULL << OVS_KEY_ATTR_TUNNEL)) {
764         if (ipv4_tun_from_nlattr(a[OVS_KEY_ATTR_TUNNEL], match,
765                      is_mask, log) < 0)
766             return -EINVAL;
767         *attrs &= ~(1ULL << OVS_KEY_ATTR_TUNNEL);
768     }
769     return 0;
770 }
.fi
.SS "static struct \fBsw_flow_actions\fP* nla_alloc_flow_actions (int size, \fBbool\fP log)\fC [static]\fP"

.PP
.nf
1535 {
1536     struct sw_flow_actions *sfa;
1537 
1538     if (size > MAX_ACTIONS_BUFSIZE) {
1539         OVS_NLERR(log, "Flow action size %u bytes exceeds max", size);
1540         return ERR_PTR(-EINVAL);
1541     }
1542 
1543     sfa = kmalloc(sizeof(*sfa) + size, GFP_KERNEL);
1544     if (!sfa)
1545         return ERR_PTR(-ENOMEM);
1546 
1547     sfa->actions_len = 0;
1548     return sfa;
1549 }
.fi
.SS "static void nlattr_set (struct nlattr * attr, u8 val, const struct \fBovs_len_tbl\fP * tbl)\fC [static]\fP"

.PP
.nf
1008 {
1009     struct nlattr *nla;
1010     int rem;
1011 
1012     /* The nlattr stream should already have been validated */
1013     nla_for_each_nested(nla, attr, rem) {
1014         if (tbl && tbl[nla_type(nla)]\&.len == OVS_ATTR_NESTED)
1015             nlattr_set(nla, val, tbl[nla_type(nla)]\&.next);
1016         else
1017             memset(nla_data(nla), val, nla_len(nla));
1018     }
1019 }
.fi
.SS "size_t ovs_key_attr_size (void)"

.PP
.nf
280 {
281     /* Whenever adding new OVS_KEY_ FIELDS, we should consider
282      * updating this function\&.
283      */
284     BUILD_BUG_ON(OVS_KEY_ATTR_TUNNEL_INFO != 22);
285 
286     return    nla_total_size(4)   /* OVS_KEY_ATTR_PRIORITY */
287         + nla_total_size(0)   /* OVS_KEY_ATTR_TUNNEL */
288           + ovs_tun_key_attr_size()
289         + nla_total_size(4)   /* OVS_KEY_ATTR_IN_PORT */
290         + nla_total_size(4)   /* OVS_KEY_ATTR_SKB_MARK */
291         + nla_total_size(4)   /* OVS_KEY_ATTR_DP_HASH */
292         + nla_total_size(4)   /* OVS_KEY_ATTR_RECIRC_ID */
293         + nla_total_size(12)  /* OVS_KEY_ATTR_ETHERNET */
294         + nla_total_size(2)   /* OVS_KEY_ATTR_ETHERTYPE */
295         + nla_total_size(4)   /* OVS_KEY_ATTR_VLAN */
296         + nla_total_size(0)   /* OVS_KEY_ATTR_ENCAP */
297         + nla_total_size(2)   /* OVS_KEY_ATTR_ETHERTYPE */
298         + nla_total_size(40)  /* OVS_KEY_ATTR_IPV6 */
299         + nla_total_size(2)   /* OVS_KEY_ATTR_ICMPV6 */
300         + nla_total_size(28); /* OVS_KEY_ATTR_ND */
301 }
.fi
.SS "static int ovs_key_from_nlattrs (struct \fBsw_flow_match\fP * match, u64 attrs, const struct nlattr ** a, \fBbool\fP is_mask, \fBbool\fP log)\fC [static]\fP"

.PP
.nf
775 {
776     int err;
777 
778     err = metadata_from_nlattrs(match, &attrs, a, is_mask, log);
779     if (err)
780         return err;
781 
782     if (attrs & (1ULL << OVS_KEY_ATTR_ETHERNET)) {
783         const struct ovs_key_ethernet *eth_key;
784 
785         eth_key = nla_data(a[OVS_KEY_ATTR_ETHERNET]);
786         SW_FLOW_KEY_MEMCPY(match, eth\&.src,
787                 eth_key->eth_src, ETH_ALEN, is_mask);
788         SW_FLOW_KEY_MEMCPY(match, eth\&.dst,
789                 eth_key->eth_dst, ETH_ALEN, is_mask);
790         attrs &= ~(1ULL << OVS_KEY_ATTR_ETHERNET);
791     }
792 
793     if (attrs & (1ULL << OVS_KEY_ATTR_VLAN)) {
794         __be16 tci;
795 
796         tci = nla_get_be16(a[OVS_KEY_ATTR_VLAN]);
797         if (!(tci & htons(VLAN_TAG_PRESENT))) {
798             if (is_mask)
799                 OVS_NLERR(log, "VLAN TCI mask does not have exact match for VLAN_TAG_PRESENT bit\&.");
800             else
801                 OVS_NLERR(log, "VLAN TCI does not have VLAN_TAG_PRESENT bit set\&.");
802 
803             return -EINVAL;
804         }
805 
806         SW_FLOW_KEY_PUT(match, eth\&.tci, tci, is_mask);
807         attrs &= ~(1ULL << OVS_KEY_ATTR_VLAN);
808     }
809 
810     if (attrs & (1ULL << OVS_KEY_ATTR_ETHERTYPE)) {
811         __be16 eth_type;
812 
813         eth_type = nla_get_be16(a[OVS_KEY_ATTR_ETHERTYPE]);
814         if (is_mask) {
815             /* Always exact match EtherType\&. */
816             eth_type = htons(0xffff);
817         } else if (!eth_proto_is_802_3(eth_type)) {
818             OVS_NLERR(log, "EtherType %x is less than min %x",
819                   ntohs(eth_type), ETH_P_802_3_MIN);
820             return -EINVAL;
821         }
822 
823         SW_FLOW_KEY_PUT(match, eth\&.type, eth_type, is_mask);
824         attrs &= ~(1ULL << OVS_KEY_ATTR_ETHERTYPE);
825     } else if (!is_mask) {
826         SW_FLOW_KEY_PUT(match, eth\&.type, htons(ETH_P_802_2), is_mask);
827     }
828 
829     if (attrs & (1ULL << OVS_KEY_ATTR_IPV4)) {
830         const struct ovs_key_ipv4 *ipv4_key;
831 
832         ipv4_key = nla_data(a[OVS_KEY_ATTR_IPV4]);
833         if (!is_mask && ipv4_key->ipv4_frag > OVS_FRAG_TYPE_MAX) {
834             OVS_NLERR(log, "IPv4 frag type %d is out of range max %d",
835                   ipv4_key->ipv4_frag, OVS_FRAG_TYPE_MAX);
836             return -EINVAL;
837         }
838         SW_FLOW_KEY_PUT(match, ip\&.proto,
839                 ipv4_key->ipv4_proto, is_mask);
840         SW_FLOW_KEY_PUT(match, ip\&.tos,
841                 ipv4_key->ipv4_tos, is_mask);
842         SW_FLOW_KEY_PUT(match, ip\&.ttl,
843                 ipv4_key->ipv4_ttl, is_mask);
844         SW_FLOW_KEY_PUT(match, ip\&.frag,
845                 ipv4_key->ipv4_frag, is_mask);
846         SW_FLOW_KEY_PUT(match, ipv4\&.addr\&.src,
847                 ipv4_key->ipv4_src, is_mask);
848         SW_FLOW_KEY_PUT(match, ipv4\&.addr\&.dst,
849                 ipv4_key->ipv4_dst, is_mask);
850         attrs &= ~(1ULL << OVS_KEY_ATTR_IPV4);
851     }
852 
853     if (attrs & (1ULL << OVS_KEY_ATTR_IPV6)) {
854         const struct ovs_key_ipv6 *ipv6_key;
855 
856         ipv6_key = nla_data(a[OVS_KEY_ATTR_IPV6]);
857         if (!is_mask && ipv6_key->ipv6_frag > OVS_FRAG_TYPE_MAX) {
858             OVS_NLERR(log, "IPv6 frag type %d is out of range max %d",
859                   ipv6_key->ipv6_frag, OVS_FRAG_TYPE_MAX);
860             return -EINVAL;
861         }
862 
863         if (!is_mask && ipv6_key->ipv6_label & htonl(0xFFF00000)) {
864             OVS_NLERR(log,
865                   "Invalid IPv6 flow label value (value=%x, max=%x)\&.",
866                   ntohl(ipv6_key->ipv6_label), (1 << 20) - 1);
867             return -EINVAL;
868         }
869 
870         SW_FLOW_KEY_PUT(match, ipv6\&.label,
871                 ipv6_key->ipv6_label, is_mask);
872         SW_FLOW_KEY_PUT(match, ip\&.proto,
873                 ipv6_key->ipv6_proto, is_mask);
874         SW_FLOW_KEY_PUT(match, ip\&.tos,
875                 ipv6_key->ipv6_tclass, is_mask);
876         SW_FLOW_KEY_PUT(match, ip\&.ttl,
877                 ipv6_key->ipv6_hlimit, is_mask);
878         SW_FLOW_KEY_PUT(match, ip\&.frag,
879                 ipv6_key->ipv6_frag, is_mask);
880         SW_FLOW_KEY_MEMCPY(match, ipv6\&.addr\&.src,
881                 ipv6_key->ipv6_src,
882                 sizeof(match->key->ipv6\&.addr\&.src),
883                 is_mask);
884         SW_FLOW_KEY_MEMCPY(match, ipv6\&.addr\&.dst,
885                 ipv6_key->ipv6_dst,
886                 sizeof(match->key->ipv6\&.addr\&.dst),
887                 is_mask);
888 
889         attrs &= ~(1ULL << OVS_KEY_ATTR_IPV6);
890     }
891 
892     if (attrs & (1ULL << OVS_KEY_ATTR_ARP)) {
893         const struct ovs_key_arp *arp_key;
894 
895         arp_key = nla_data(a[OVS_KEY_ATTR_ARP]);
896         if (!is_mask && (arp_key->arp_op & htons(0xff00))) {
897             OVS_NLERR(log, "Unknown ARP opcode (opcode=%d)\&.",
898                   arp_key->arp_op);
899             return -EINVAL;
900         }
901 
902         SW_FLOW_KEY_PUT(match, ipv4\&.addr\&.src,
903                 arp_key->arp_sip, is_mask);
904         SW_FLOW_KEY_PUT(match, ipv4\&.addr\&.dst,
905             arp_key->arp_tip, is_mask);
906         SW_FLOW_KEY_PUT(match, ip\&.proto,
907                 ntohs(arp_key->arp_op), is_mask);
908         SW_FLOW_KEY_MEMCPY(match, ipv4\&.arp\&.sha,
909                 arp_key->arp_sha, ETH_ALEN, is_mask);
910         SW_FLOW_KEY_MEMCPY(match, ipv4\&.arp\&.tha,
911                 arp_key->arp_tha, ETH_ALEN, is_mask);
912 
913         attrs &= ~(1ULL << OVS_KEY_ATTR_ARP);
914     }
915 
916     if (attrs & (1ULL << OVS_KEY_ATTR_MPLS)) {
917         const struct ovs_key_mpls *mpls_key;
918 
919         mpls_key = nla_data(a[OVS_KEY_ATTR_MPLS]);
920         SW_FLOW_KEY_PUT(match, mpls\&.top_lse,
921                 mpls_key->mpls_lse, is_mask);
922 
923         attrs &= ~(1ULL << OVS_KEY_ATTR_MPLS);
924     }
925 
926     if (attrs & (1ULL << OVS_KEY_ATTR_TCP)) {
927         const struct ovs_key_tcp *tcp_key;
928 
929         tcp_key = nla_data(a[OVS_KEY_ATTR_TCP]);
930         SW_FLOW_KEY_PUT(match, tp\&.src, tcp_key->tcp_src, is_mask);
931         SW_FLOW_KEY_PUT(match, tp\&.dst, tcp_key->tcp_dst, is_mask);
932         attrs &= ~(1ULL << OVS_KEY_ATTR_TCP);
933     }
934 
935     if (attrs & (1ULL << OVS_KEY_ATTR_TCP_FLAGS)) {
936         SW_FLOW_KEY_PUT(match, tp\&.flags,
937                 nla_get_be16(a[OVS_KEY_ATTR_TCP_FLAGS]),
938                 is_mask);
939         attrs &= ~(1ULL << OVS_KEY_ATTR_TCP_FLAGS);
940     }
941 
942     if (attrs & (1ULL << OVS_KEY_ATTR_UDP)) {
943         const struct ovs_key_udp *udp_key;
944 
945         udp_key = nla_data(a[OVS_KEY_ATTR_UDP]);
946         SW_FLOW_KEY_PUT(match, tp\&.src, udp_key->udp_src, is_mask);
947         SW_FLOW_KEY_PUT(match, tp\&.dst, udp_key->udp_dst, is_mask);
948         attrs &= ~(1ULL << OVS_KEY_ATTR_UDP);
949     }
950 
951     if (attrs & (1ULL << OVS_KEY_ATTR_SCTP)) {
952         const struct ovs_key_sctp *sctp_key;
953 
954         sctp_key = nla_data(a[OVS_KEY_ATTR_SCTP]);
955         SW_FLOW_KEY_PUT(match, tp\&.src, sctp_key->sctp_src, is_mask);
956         SW_FLOW_KEY_PUT(match, tp\&.dst, sctp_key->sctp_dst, is_mask);
957         attrs &= ~(1ULL << OVS_KEY_ATTR_SCTP);
958     }
959 
960     if (attrs & (1ULL << OVS_KEY_ATTR_ICMP)) {
961         const struct ovs_key_icmp *icmp_key;
962 
963         icmp_key = nla_data(a[OVS_KEY_ATTR_ICMP]);
964         SW_FLOW_KEY_PUT(match, tp\&.src,
965                 htons(icmp_key->icmp_type), is_mask);
966         SW_FLOW_KEY_PUT(match, tp\&.dst,
967                 htons(icmp_key->icmp_code), is_mask);
968         attrs &= ~(1ULL << OVS_KEY_ATTR_ICMP);
969     }
970 
971     if (attrs & (1ULL << OVS_KEY_ATTR_ICMPV6)) {
972         const struct ovs_key_icmpv6 *icmpv6_key;
973 
974         icmpv6_key = nla_data(a[OVS_KEY_ATTR_ICMPV6]);
975         SW_FLOW_KEY_PUT(match, tp\&.src,
976                 htons(icmpv6_key->icmpv6_type), is_mask);
977         SW_FLOW_KEY_PUT(match, tp\&.dst,
978                 htons(icmpv6_key->icmpv6_code), is_mask);
979         attrs &= ~(1ULL << OVS_KEY_ATTR_ICMPV6);
980     }
981 
982     if (attrs & (1ULL << OVS_KEY_ATTR_ND)) {
983         const struct ovs_key_nd *nd_key;
984 
985         nd_key = nla_data(a[OVS_KEY_ATTR_ND]);
986         SW_FLOW_KEY_MEMCPY(match, ipv6\&.nd\&.target,
987             nd_key->nd_target,
988             sizeof(match->key->ipv6\&.nd\&.target),
989             is_mask);
990         SW_FLOW_KEY_MEMCPY(match, ipv6\&.nd\&.sll,
991             nd_key->nd_sll, ETH_ALEN, is_mask);
992         SW_FLOW_KEY_MEMCPY(match, ipv6\&.nd\&.tll,
993                 nd_key->nd_tll, ETH_ALEN, is_mask);
994         attrs &= ~(1ULL << OVS_KEY_ATTR_ND);
995     }
996 
997     if (attrs != 0) {
998         OVS_NLERR(log, "Unknown key attributes %llx",
999               (unsigned long long)attrs);
1000         return -EINVAL;
1001     }
1002 
1003     return 0;
1004 }
.fi
.SS "void ovs_match_init (struct \fBsw_flow_match\fP * match, struct \fBsw_flow_key\fP * key, struct \fBsw_flow_mask\fP * mask)"

.PP
.nf
1714 {
1715     memset(match, 0, sizeof(*match));
1716     match->key = key;
1717     match->mask = mask;
1718 
1719     memset(key, 0, sizeof(*key));
1720 
1721     if (mask) {
1722         memset(&mask->key, 0, sizeof(mask->key));
1723         mask->range\&.start = mask->range\&.end = 0;
1724     }
1725 }
.fi
.SS "int ovs_nla_copy_actions (const struct nlattr * attr, const struct \fBsw_flow_key\fP * key, struct \fBsw_flow_actions\fP ** sfa, \fBbool\fP log)"

.PP
.nf
2182 {
2183     int err;
2184 
2185     *sfa = nla_alloc_flow_actions(nla_len(attr), log);
2186     if (IS_ERR(*sfa))
2187         return PTR_ERR(*sfa);
2188 
2189     err = __ovs_nla_copy_actions(attr, key, 0, sfa, key->eth\&.type,
2190                      key->eth\&.tci, log);
2191     if (err)
2192         kfree(*sfa);
2193 
2194     return err;
2195 }
.fi
.SS "void ovs_nla_free_flow_actions (struct \fBsw_flow_actions\fP * sf_acts)"

.PP
.nf
1563 {
1564     call_rcu(&sf_acts->rcu, rcu_free_acts_callback);
1565 }
.fi
.SS "int ovs_nla_get_flow_metadata (const struct nlattr * attr, struct \fBsw_flow_key\fP * key, \fBbool\fP log)"
ovs_nla_get_flow_metadata - parses Netlink attributes into a flow key\&. : Receives extracted in_port, priority, tun_key and skb_mark\&. : Netlink attribute holding nested OVS_KEY_ATTR_* Netlink attribute sequence\&. : Boolean to allow kernel error logging\&. Normally true, but when probing for feature compatibility this should be passed in as false to suppress unnecessary error logging\&.
.PP
This parses a series of Netlink attributes that form a flow key, which must take the same form accepted by flow_from_nlattrs(), but only enough of it to get the metadata, that is, the parts of the flow key that cannot be extracted from the packet itself\&. 
.PP
.nf
1255 {
1256     const struct nlattr *a[OVS_KEY_ATTR_MAX + 1];
1257     struct sw_flow_match match;
1258     u64 attrs = 0;
1259     int err;
1260 
1261     err = parse_flow_nlattrs(attr, a, &attrs, log);
1262     if (err)
1263         return -EINVAL;
1264 
1265     memset(&match, 0, sizeof(match));
1266     match\&.key = key;
1267 
1268     memset(key, 0, OVS_SW_FLOW_KEY_METADATA_SIZE);
1269     key->phy\&.in_port = DP_MAX_PORTS;
1270 
1271     return metadata_from_nlattrs(&match, &attrs, a, false, log);
1272 }
.fi
.SS "int ovs_nla_get_identifier (struct \fBsw_flow_id\fP * sfid, const struct nlattr * ufid, const struct \fBsw_flow_key\fP * key, \fBbool\fP log)"

.PP
.nf
1216 {
1217     struct sw_flow_key *new_key;
1218 
1219     if (ovs_nla_get_ufid(sfid, ufid, log))
1220         return 0;
1221 
1222     /* If UFID was not provided, use unmasked key\&. */
1223     new_key = kmalloc(sizeof(*new_key), GFP_KERNEL);
1224     if (!new_key)
1225         return -ENOMEM;
1226     memcpy(new_key, key, sizeof(*key));
1227     sfid->unmasked_key = new_key;
1228 
1229     return 0;
1230 }
.fi
.SS "int ovs_nla_get_match (struct \fBsw_flow_match\fP * match, const struct nlattr * nla_key, const struct nlattr * nla_mask, \fBbool\fP log)"
ovs_nla_get_match - parses Netlink attributes into a flow key and mask\&. In case the 'mask' is NULL, the flow is treated as exact match flow\&. Otherwise, it is treated as a wildcarded flow, except the mask does not include any don't care bit\&. : receives the extracted flow match information\&. : Netlink attribute holding nested OVS_KEY_ATTR_* Netlink attribute sequence\&. The fields should of the packet that triggered the creation of this flow\&. : Optional\&. Netlink attribute holding nested OVS_KEY_ATTR_* Netlink attribute specifies the mask field of the wildcarded flow\&. : Boolean to allow kernel error logging\&. Normally true, but when probing for feature compatibility this should be passed in as false to suppress unnecessary error logging\&. 
.PP
.nf
1045 {
1046     const struct nlattr *a[OVS_KEY_ATTR_MAX + 1];
1047     const struct nlattr *encap;
1048     struct nlattr *newmask = NULL;
1049     u64 key_attrs = 0;
1050     u64 mask_attrs = 0;
1051     bool encap_valid = false;
1052     int err;
1053 
1054     err = parse_flow_nlattrs(nla_key, a, &key_attrs, log);
1055     if (err)
1056         return err;
1057 
1058     if ((key_attrs & (1ULL << OVS_KEY_ATTR_ETHERNET)) &&
1059         (key_attrs & (1ULL << OVS_KEY_ATTR_ETHERTYPE)) &&
1060         (nla_get_be16(a[OVS_KEY_ATTR_ETHERTYPE]) == htons(ETH_P_8021Q))) {
1061         __be16 tci;
1062 
1063         if (!((key_attrs & (1ULL << OVS_KEY_ATTR_VLAN)) &&
1064               (key_attrs & (1ULL << OVS_KEY_ATTR_ENCAP)))) {
1065             OVS_NLERR(log, "Invalid Vlan frame\&.");
1066             return -EINVAL;
1067         }
1068 
1069         key_attrs &= ~(1ULL << OVS_KEY_ATTR_ETHERTYPE);
1070         tci = nla_get_be16(a[OVS_KEY_ATTR_VLAN]);
1071         encap = a[OVS_KEY_ATTR_ENCAP];
1072         key_attrs &= ~(1ULL << OVS_KEY_ATTR_ENCAP);
1073         encap_valid = true;
1074 
1075         if (tci & htons(VLAN_TAG_PRESENT)) {
1076             err = parse_flow_nlattrs(encap, a, &key_attrs, log);
1077             if (err)
1078                 return err;
1079         } else if (!tci) {
1080             /* Corner case for truncated 802\&.1Q header\&. */
1081             if (nla_len(encap)) {
1082                 OVS_NLERR(log, "Truncated 802\&.1Q header has non-zero encap attribute\&.");
1083                 return -EINVAL;
1084             }
1085         } else {
1086             OVS_NLERR(log, "Encap attr is set for non-VLAN frame");
1087             return  -EINVAL;
1088         }
1089     }
1090 
1091     err = ovs_key_from_nlattrs(match, key_attrs, a, false, log);
1092     if (err)
1093         return err;
1094 
1095     if (match->mask) {
1096         if (!nla_mask) {
1097             /* Create an exact match mask\&. We need to set to 0xff
1098              * all the 'match->mask' fields that have been touched
1099              * in 'match->key'\&. We cannot simply memset
1100              * 'match->mask', because padding bytes and fields not
1101              * specified in 'match->key' should be left to 0\&.
1102              * Instead, we use a stream of netlink attributes,
1103              * copied from 'key' and set to 0xff\&.
1104              * ovs_key_from_nlattrs() will take care of filling
1105              * 'match->mask' appropriately\&.
1106              */
1107             newmask = kmemdup(nla_key,
1108                       nla_total_size(nla_len(nla_key)),
1109                       GFP_KERNEL);
1110             if (!newmask)
1111                 return -ENOMEM;
1112 
1113             mask_set_nlattr(newmask, 0xff);
1114 
1115             /* The userspace does not send tunnel attributes that
1116              * are 0, but we should not wildcard them nonetheless\&.
1117              */
1118             if (match->key->tun_key\&.ipv4_dst)
1119                 SW_FLOW_KEY_MEMSET_FIELD(match, tun_key,
1120                              0xff, true);
1121 
1122             nla_mask = newmask;
1123         }
1124 
1125         err = parse_flow_mask_nlattrs(nla_mask, a, &mask_attrs, log);
1126         if (err)
1127             goto free_newmask;
1128 
1129         /* Always match on tci\&. */
1130         SW_FLOW_KEY_PUT(match, eth\&.tci, htons(0xffff), true);
1131 
1132         if (mask_attrs & 1ULL << OVS_KEY_ATTR_ENCAP) {
1133             __be16 eth_type = 0;
1134             __be16 tci = 0;
1135 
1136             if (!encap_valid) {
1137                 OVS_NLERR(log, "Encap mask attribute is set for non-VLAN frame\&.");
1138                 err = -EINVAL;
1139                 goto free_newmask;
1140             }
1141 
1142             mask_attrs &= ~(1ULL << OVS_KEY_ATTR_ENCAP);
1143             if (a[OVS_KEY_ATTR_ETHERTYPE])
1144                 eth_type = nla_get_be16(a[OVS_KEY_ATTR_ETHERTYPE]);
1145 
1146             if (eth_type == htons(0xffff)) {
1147                 mask_attrs &= ~(1ULL << OVS_KEY_ATTR_ETHERTYPE);
1148                 encap = a[OVS_KEY_ATTR_ENCAP];
1149                 err = parse_flow_mask_nlattrs(encap, a,
1150                                   &mask_attrs, log);
1151                 if (err)
1152                     goto free_newmask;
1153             } else {
1154                 OVS_NLERR(log, "VLAN frames must have an exact match on the TPID (mask=%x)\&.",
1155                       ntohs(eth_type));
1156                 err = -EINVAL;
1157                 goto free_newmask;
1158             }
1159 
1160             if (a[OVS_KEY_ATTR_VLAN])
1161                 tci = nla_get_be16(a[OVS_KEY_ATTR_VLAN]);
1162 
1163             if (!(tci & htons(VLAN_TAG_PRESENT))) {
1164                 OVS_NLERR(log, "VLAN tag present bit must have an exact match (tci_mask=%x)\&.",
1165                       ntohs(tci));
1166                 err = -EINVAL;
1167                 goto free_newmask;
1168             }
1169         }
1170 
1171         err = ovs_key_from_nlattrs(match, mask_attrs, a, true, log);
1172         if (err)
1173             goto free_newmask;
1174     }
1175 
1176     if (!match_validate(match, key_attrs, mask_attrs, log))
1177         err = -EINVAL;
1178 
1179 free_newmask:
1180     kfree(newmask);
1181     return err;
1182 }
.fi
.SS "\fBbool\fP ovs_nla_get_ufid (struct \fBsw_flow_id\fP * sfid, const struct nlattr * attr, \fBbool\fP log)"

.PP
.nf
1206 {
1207     sfid->ufid_len = get_ufid_len(attr, log);
1208     if (sfid->ufid_len)
1209         memcpy(sfid->ufid, nla_data(attr), sfid->ufid_len);
1210 
1211     return sfid->ufid_len;
1212 }
.fi
.SS "u32 ovs_nla_get_ufid_flags (const struct nlattr * attr)"

.PP
.nf
1233 {
1234     return attr ? nla_get_u32(attr) : 0;
1235 }
.fi
.SS "int ovs_nla_put_actions (const struct nlattr * attr, int len, struct sk_buff * skb)"

.PP
.nf
2282 {
2283     const struct nlattr *a;
2284     int rem, err;
2285 
2286     nla_for_each_attr(a, attr, len, rem) {
2287         int type = nla_type(a);
2288 
2289         switch (type) {
2290         case OVS_ACTION_ATTR_SET:
2291             err = set_action_to_attr(a, skb);
2292             if (err)
2293                 return err;
2294             break;
2295 
2296         case OVS_ACTION_ATTR_SET_TO_MASKED:
2297             err = masked_set_action_to_set_action_attr(a, skb);
2298             if (err)
2299                 return err;
2300             break;
2301 
2302         case OVS_ACTION_ATTR_SAMPLE:
2303             err = sample_action_to_attr(a, skb);
2304             if (err)
2305                 return err;
2306             break;
2307         default:
2308             if (nla_put(skb, type, nla_len(a), nla_data(a)))
2309                 return -EMSGSIZE;
2310             break;
2311         }
2312     }
2313 
2314     return 0;
2315 }
.fi
.SS "int ovs_nla_put_egress_tunnel_key (struct sk_buff * skb, const struct \fBovs_tunnel_info\fP * egress_tun_info)"

.PP
.nf
710 {
711     return __ipv4_tun_to_nlattr(skb, &egress_tun_info->tunnel,
712                     egress_tun_info->options,
713                     egress_tun_info->options_len);
714 }
.fi
.SS "int ovs_nla_put_identifier (const struct \fBsw_flow\fP * flow, struct sk_buff * skb)"

.PP
.nf
1509 {
1510     if (ovs_identifier_is_ufid(&flow->id))
1511         return nla_put(skb, OVS_FLOW_ATTR_UFID, flow->id\&.ufid_len,
1512                    flow->id\&.ufid);
1513 
1514     return ovs_nla_put_key(flow->id\&.unmasked_key, flow->id\&.unmasked_key,
1515                    OVS_FLOW_ATTR_KEY, false, skb);
1516 }
.fi
.SS "int ovs_nla_put_key (const struct \fBsw_flow_key\fP * swkey, const struct \fBsw_flow_key\fP * output, int attr, \fBbool\fP is_mask, struct sk_buff * skb)"

.PP
.nf
1492 {
1493     int err;
1494     struct nlattr *nla;
1495 
1496     nla = nla_nest_start(skb, attr);
1497     if (!nla)
1498         return -EMSGSIZE;
1499     err = __ovs_nla_put_key(swkey, output, is_mask, skb);
1500     if (err)
1501         return err;
1502     nla_nest_end(skb, nla);
1503 
1504     return 0;
1505 }
.fi
.SS "int ovs_nla_put_mask (const struct \fBsw_flow\fP * flow, struct sk_buff * skb)"

.PP
.nf
1527 {
1528     return ovs_nla_put_key(&flow->key, &flow->mask->key,
1529                 OVS_FLOW_ATTR_MASK, true, skb);
1530 }
.fi
.SS "int ovs_nla_put_masked_key (const struct \fBsw_flow\fP * flow, struct sk_buff * skb)"

.PP
.nf
1520 {
1521     return ovs_nla_put_key(&flow->key, &flow->key,
1522                 OVS_FLOW_ATTR_KEY, false, skb);
1523 }
.fi
.SS "size_t ovs_tun_key_attr_size (void)"

.PP
.nf
259 {
260     /* Whenever adding new OVS_TUNNEL_KEY_ FIELDS, we should consider
261      * updating this function\&.
262      */
263     return    nla_total_size(8)    /* OVS_TUNNEL_KEY_ATTR_ID */
264         + nla_total_size(4)    /* OVS_TUNNEL_KEY_ATTR_IPV4_SRC */
265         + nla_total_size(4)    /* OVS_TUNNEL_KEY_ATTR_IPV4_DST */
266         + nla_total_size(1)    /* OVS_TUNNEL_KEY_ATTR_TOS */
267         + nla_total_size(1)    /* OVS_TUNNEL_KEY_ATTR_TTL */
268         + nla_total_size(0)    /* OVS_TUNNEL_KEY_ATTR_DONT_FRAGMENT */
269         + nla_total_size(0)    /* OVS_TUNNEL_KEY_ATTR_CSUM */
270         + nla_total_size(0)    /* OVS_TUNNEL_KEY_ATTR_OAM */
271         + nla_total_size(256)  /* OVS_TUNNEL_KEY_ATTR_GENEVE_OPTS */
272         /* OVS_TUNNEL_KEY_ATTR_VXLAN_OPTS is mutually exclusive with
273          * OVS_TUNNEL_KEY_ATTR_GENEVE_OPTS and covered by it\&.
274          */
275         + nla_total_size(2)    /* OVS_TUNNEL_KEY_ATTR_TP_SRC */
276         + nla_total_size(2);   /* OVS_TUNNEL_KEY_ATTR_TP_DST */
277 }
.fi
.SS "static int parse_flow_mask_nlattrs (const struct nlattr * attr, const struct nlattr * a[], u64 * attrsp, \fBbool\fP log)\fC [static]\fP"

.PP
.nf
406 {
407     return __parse_flow_nlattrs(attr, a, attrsp, log, true);
408 }
.fi
.SS "static int parse_flow_nlattrs (const struct nlattr * attr, const struct nlattr * a[], u64 * attrsp, \fBbool\fP log)\fC [static]\fP"

.PP
.nf
413 {
414     return __parse_flow_nlattrs(attr, a, attrsp, log, false);
415 }
.fi
.SS "static void rcu_free_acts_callback (struct rcu_head * rcu)\fC [static]\fP"

.PP
.nf
1553 {
1554     struct sw_flow_actions *sf_acts = container_of(rcu,
1555             struct sw_flow_actions, rcu);
1556     kfree(sf_acts);
1557 }
.fi
.SS "static struct nlattr* reserve_sfa_size (struct \fBsw_flow_actions\fP ** sfa, int attr_len, \fBbool\fP log)\fC [static]\fP"

.PP
.nf
1569 {
1570 
1571     struct sw_flow_actions *acts;
1572     int new_acts_size;
1573     int req_size = NLA_ALIGN(attr_len);
1574     int next_offset = offsetof(struct sw_flow_actions, actions) +
1575                     (*sfa)->actions_len;
1576 
1577     if (req_size <= (ksize(*sfa) - next_offset))
1578         goto out;
1579 
1580     new_acts_size = ksize(*sfa) * 2;
1581 
1582     if (new_acts_size > MAX_ACTIONS_BUFSIZE) {
1583         if ((MAX_ACTIONS_BUFSIZE - next_offset) < req_size)
1584             return ERR_PTR(-EMSGSIZE);
1585         new_acts_size = MAX_ACTIONS_BUFSIZE;
1586     }
1587 
1588     acts = nla_alloc_flow_actions(new_acts_size, log);
1589     if (IS_ERR(acts))
1590         return (void *)acts;
1591 
1592     memcpy(acts->actions, (*sfa)->actions, (*sfa)->actions_len);
1593     acts->actions_len = (*sfa)->actions_len;
1594     kfree(*sfa);
1595     *sfa = acts;
1596 
1597 out:
1598     (*sfa)->actions_len += req_size;
1599     return  (struct nlattr *) ((unsigned char *)(*sfa) + next_offset);
1600 }
.fi
.SS "static int sample_action_to_attr (const struct nlattr * attr, struct sk_buff * skb)\fC [static]\fP"

.PP
.nf
2198 {
2199     const struct nlattr *a;
2200     struct nlattr *start;
2201     int err = 0, rem;
2202 
2203     start = nla_nest_start(skb, OVS_ACTION_ATTR_SAMPLE);
2204     if (!start)
2205         return -EMSGSIZE;
2206 
2207     nla_for_each_nested(a, attr, rem) {
2208         int type = nla_type(a);
2209         struct nlattr *st_sample;
2210 
2211         switch (type) {
2212         case OVS_SAMPLE_ATTR_PROBABILITY:
2213             if (nla_put(skb, OVS_SAMPLE_ATTR_PROBABILITY,
2214                     sizeof(u32), nla_data(a)))
2215                 return -EMSGSIZE;
2216             break;
2217         case OVS_SAMPLE_ATTR_ACTIONS:
2218             st_sample = nla_nest_start(skb, OVS_SAMPLE_ATTR_ACTIONS);
2219             if (!st_sample)
2220                 return -EMSGSIZE;
2221             err = ovs_nla_put_actions(nla_data(a), nla_len(a), skb);
2222             if (err)
2223                 return err;
2224             nla_nest_end(skb, st_sample);
2225             break;
2226         }
2227     }
2228 
2229     nla_nest_end(skb, start);
2230     return err;
2231 }
.fi
.SS "static int set_action_to_attr (const struct nlattr * a, struct sk_buff * skb)\fC [static]\fP"

.PP
.nf
2234 {
2235     const struct nlattr *ovs_key = nla_data(a);
2236     int key_type = nla_type(ovs_key);
2237     struct nlattr *start;
2238     int err;
2239 
2240     switch (key_type) {
2241     case OVS_KEY_ATTR_TUNNEL_INFO: {
2242         struct ovs_tunnel_info *tun_info = nla_data(ovs_key);
2243 
2244         start = nla_nest_start(skb, OVS_ACTION_ATTR_SET);
2245         if (!start)
2246             return -EMSGSIZE;
2247 
2248         err = ipv4_tun_to_nlattr(skb, &tun_info->tunnel,
2249                      tun_info->options_len ?
2250                         tun_info->options : NULL,
2251                      tun_info->options_len);
2252         if (err)
2253             return err;
2254         nla_nest_end(skb, start);
2255         break;
2256     }
2257     default:
2258         if (nla_put(skb, OVS_ACTION_ATTR_SET, nla_len(a), ovs_key))
2259             return -EMSGSIZE;
2260         break;
2261     }
2262 
2263     return 0;
2264 }
.fi
.SS "static void update_range (struct \fBsw_flow_match\fP * match, size_t offset, size_t size, \fBbool\fP is_mask)\fC [static]\fP"

.PP
.nf
63 {
64     struct sw_flow_key_range *range;
65     size_t start = rounddown(offset, sizeof(long));
66     size_t end = roundup(offset + size, sizeof(long));
67 
68     if (!is_mask)
69         range = &match->range;
70     else
71         range = &match->mask->range;
72 
73     if (range->start == range->end) {
74         range->start = start;
75         range->end = end;
76         return;
77     }
78 
79     if (range->start > start)
80         range->start = start;
81 
82     if (range->end < end)
83         range->end = end;
84 }
.fi
.SS "static int validate_and_copy_sample (const struct nlattr * attr, const struct \fBsw_flow_key\fP * key, int depth, struct \fBsw_flow_actions\fP ** sfa, __be16 eth_type, __be16 vlan_tci, \fBbool\fP log)\fC [static]\fP"

.PP
.nf
1664 {
1665     const struct nlattr *attrs[OVS_SAMPLE_ATTR_MAX + 1];
1666     const struct nlattr *probability, *actions;
1667     const struct nlattr *a;
1668     int rem, start, err, st_acts;
1669 
1670     memset(attrs, 0, sizeof(attrs));
1671     nla_for_each_nested(a, attr, rem) {
1672         int type = nla_type(a);
1673         if (!type || type > OVS_SAMPLE_ATTR_MAX || attrs[type])
1674             return -EINVAL;
1675         attrs[type] = a;
1676     }
1677     if (rem)
1678         return -EINVAL;
1679 
1680     probability = attrs[OVS_SAMPLE_ATTR_PROBABILITY];
1681     if (!probability || nla_len(probability) != sizeof(u32))
1682         return -EINVAL;
1683 
1684     actions = attrs[OVS_SAMPLE_ATTR_ACTIONS];
1685     if (!actions || (nla_len(actions) && nla_len(actions) < NLA_HDRLEN))
1686         return -EINVAL;
1687 
1688     /* validation done, copy sample action\&. */
1689     start = add_nested_action_start(sfa, OVS_ACTION_ATTR_SAMPLE, log);
1690     if (start < 0)
1691         return start;
1692     err = add_action(sfa, OVS_SAMPLE_ATTR_PROBABILITY,
1693              nla_data(probability), sizeof(u32), log);
1694     if (err)
1695         return err;
1696     st_acts = add_nested_action_start(sfa, OVS_SAMPLE_ATTR_ACTIONS, log);
1697     if (st_acts < 0)
1698         return st_acts;
1699 
1700     err = __ovs_nla_copy_actions(actions, key, depth + 1, sfa,
1701                      eth_type, vlan_tci, log);
1702     if (err)
1703         return err;
1704 
1705     add_nested_action_end(*sfa, st_acts);
1706     add_nested_action_end(*sfa, start);
1707 
1708     return 0;
1709 }
.fi
.SS "static int validate_and_copy_set_tun (const struct nlattr * attr, struct \fBsw_flow_actions\fP ** sfa, \fBbool\fP log)\fC [static]\fP"

.PP
.nf
1757 {
1758     struct sw_flow_match match;
1759     struct sw_flow_key key;
1760     struct ovs_tunnel_info *tun_info;
1761     struct nlattr *a;
1762     int start, opts_type;
1763     int err = 0;
1764 
1765     ovs_match_init(&match, &key, NULL);
1766     opts_type = ipv4_tun_from_nlattr(nla_data(attr), &match, false, log);
1767     if (opts_type < 0)
1768         return opts_type;
1769 
1770     if (key\&.tun_opts_len) {
1771         switch (opts_type) {
1772         case OVS_TUNNEL_KEY_ATTR_GENEVE_OPTS:
1773             err = validate_geneve_opts(&key);
1774             if (err < 0)
1775                 return err;
1776             break;
1777         case OVS_TUNNEL_KEY_ATTR_VXLAN_OPTS:
1778             break;
1779         }
1780     };
1781 
1782     start = add_nested_action_start(sfa, OVS_ACTION_ATTR_SET, log);
1783     if (start < 0)
1784         return start;
1785 
1786     a = __add_action(sfa, OVS_KEY_ATTR_TUNNEL_INFO, NULL,
1787              sizeof(*tun_info) + key\&.tun_opts_len, log);
1788     if (IS_ERR(a))
1789         return PTR_ERR(a);
1790 
1791     tun_info = nla_data(a);
1792     tun_info->tunnel = key\&.tun_key;
1793     tun_info->options_len = key\&.tun_opts_len;
1794 
1795     if (tun_info->options_len) {
1796         /* We need to store the options in the action itself since
1797          * everything else will go away after flow setup\&. We can append
1798          * it to tun_info and then point there\&.
1799          */
1800         memcpy((tun_info + 1),
1801                TUN_METADATA_OPTS(&key, key\&.tun_opts_len), key\&.tun_opts_len);
1802         tun_info->options = (tun_info + 1);
1803     } else {
1804         tun_info->options = NULL;
1805     }
1806 
1807     add_nested_action_end(*sfa, start);
1808 
1809     return err;
1810 }
.fi
.SS "static int validate_geneve_opts (struct \fBsw_flow_key\fP * key)\fC [static]\fP"

.PP
.nf
1728 {
1729     struct geneve_opt *option;
1730     int opts_len = key->tun_opts_len;
1731     bool crit_opt = false;
1732 
1733     option = (struct geneve_opt *)TUN_METADATA_OPTS(key, key->tun_opts_len);
1734     while (opts_len > 0) {
1735         int len;
1736 
1737         if (opts_len < sizeof(*option))
1738             return -EINVAL;
1739 
1740         len = sizeof(*option) + option->length * 4;
1741         if (len > opts_len)
1742             return -EINVAL;
1743 
1744         crit_opt |= !!(option->type & GENEVE_CRIT_OPT_TYPE);
1745 
1746         option = (struct geneve_opt *)((u8 *)option + len);
1747         opts_len -= len;
1748     };
1749 
1750     key->tun_key\&.tun_flags |= crit_opt ? TUNNEL_CRIT_OPT : 0;
1751 
1752     return 0;
1753 }
.fi
.SS "static \fBbool\fP validate_masked (u8 * data, int len)\fC [static]\fP"

.PP
.nf
1816 {
1817     u8 *mask = data + len;
1818 
1819     while (len--)
1820         if (*data++ & ~*mask++)
1821             return false;
1822 
1823     return true;
1824 }
.fi
.SS "static int validate_set (const struct nlattr * a, const struct \fBsw_flow_key\fP * flow_key, struct \fBsw_flow_actions\fP ** sfa, \fBbool\fP * skip_copy, __be16 eth_type, \fBbool\fP masked, \fBbool\fP log)\fC [static]\fP"

.PP
.nf
1830 {
1831     const struct nlattr *ovs_key = nla_data(a);
1832     int key_type = nla_type(ovs_key);
1833     size_t key_len;
1834 
1835     /* There can be only one key in a action */
1836     if (nla_total_size(nla_len(ovs_key)) != nla_len(a))
1837         return -EINVAL;
1838 
1839     key_len = nla_len(ovs_key);
1840     if (masked)
1841         key_len /= 2;
1842 
1843     if (key_type > OVS_KEY_ATTR_MAX ||
1844         (ovs_key_lens[key_type]\&.len != key_len &&
1845          ovs_key_lens[key_type]\&.len != OVS_ATTR_NESTED))
1846         return -EINVAL;
1847 
1848     if (masked && !validate_masked(nla_data(ovs_key), key_len))
1849         return -EINVAL;
1850 
1851     switch (key_type) {
1852     const struct ovs_key_ipv4 *ipv4_key;
1853     const struct ovs_key_ipv6 *ipv6_key;
1854     int err;
1855 
1856     case OVS_KEY_ATTR_PRIORITY:
1857     case OVS_KEY_ATTR_SKB_MARK:
1858     case OVS_KEY_ATTR_ETHERNET:
1859         break;
1860 
1861     case OVS_KEY_ATTR_TUNNEL:
1862         if (eth_p_mpls(eth_type))
1863             return -EINVAL;
1864 
1865         if (masked)
1866             return -EINVAL; /* Masked tunnel set not supported\&. */
1867 
1868         *skip_copy = true;
1869         err = validate_and_copy_set_tun(a, sfa, log);
1870         if (err)
1871             return err;
1872         break;
1873 
1874     case OVS_KEY_ATTR_IPV4:
1875         if (eth_type != htons(ETH_P_IP))
1876             return -EINVAL;
1877 
1878         ipv4_key = nla_data(ovs_key);
1879 
1880         if (masked) {
1881             const struct ovs_key_ipv4 *mask = ipv4_key + 1;
1882 
1883             /* Non-writeable fields\&. */
1884             if (mask->ipv4_proto || mask->ipv4_frag)
1885                 return -EINVAL;
1886         } else {
1887             if (ipv4_key->ipv4_proto != flow_key->ip\&.proto)
1888                 return -EINVAL;
1889 
1890             if (ipv4_key->ipv4_frag != flow_key->ip\&.frag)
1891                 return -EINVAL;
1892         }
1893         break;
1894 
1895     case OVS_KEY_ATTR_IPV6:
1896         if (eth_type != htons(ETH_P_IPV6))
1897             return -EINVAL;
1898 
1899         ipv6_key = nla_data(ovs_key);
1900 
1901         if (masked) {
1902             const struct ovs_key_ipv6 *mask = ipv6_key + 1;
1903 
1904             /* Non-writeable fields\&. */
1905             if (mask->ipv6_proto || mask->ipv6_frag)
1906                 return -EINVAL;
1907 
1908             /* Invalid bits in the flow label mask? */
1909             if (ntohl(mask->ipv6_label) & 0xFFF00000)
1910                 return -EINVAL;
1911         } else {
1912             if (ipv6_key->ipv6_proto != flow_key->ip\&.proto)
1913                 return -EINVAL;
1914 
1915             if (ipv6_key->ipv6_frag != flow_key->ip\&.frag)
1916                 return -EINVAL;
1917         }
1918         if (ntohl(ipv6_key->ipv6_label) & 0xFFF00000)
1919             return -EINVAL;
1920 
1921         break;
1922 
1923     case OVS_KEY_ATTR_TCP:
1924         if ((eth_type != htons(ETH_P_IP) &&
1925              eth_type != htons(ETH_P_IPV6)) ||
1926             flow_key->ip\&.proto != IPPROTO_TCP)
1927             return -EINVAL;
1928 
1929         break;
1930 
1931     case OVS_KEY_ATTR_UDP:
1932         if ((eth_type != htons(ETH_P_IP) &&
1933              eth_type != htons(ETH_P_IPV6)) ||
1934             flow_key->ip\&.proto != IPPROTO_UDP)
1935             return -EINVAL;
1936 
1937         break;
1938 
1939     case OVS_KEY_ATTR_MPLS:
1940         if (!eth_p_mpls(eth_type))
1941             return -EINVAL;
1942         break;
1943 
1944     case OVS_KEY_ATTR_SCTP:
1945         if ((eth_type != htons(ETH_P_IP) &&
1946              eth_type != htons(ETH_P_IPV6)) ||
1947             flow_key->ip\&.proto != IPPROTO_SCTP)
1948             return -EINVAL;
1949 
1950         break;
1951 
1952     default:
1953         return -EINVAL;
1954     }
1955 
1956     /* Convert non-masked non-tunnel set actions to masked set actions\&. */
1957     if (!masked && key_type != OVS_KEY_ATTR_TUNNEL) {
1958         int start, len = key_len * 2;
1959         struct nlattr *at;
1960 
1961         *skip_copy = true;
1962 
1963         start = add_nested_action_start(sfa,
1964                         OVS_ACTION_ATTR_SET_TO_MASKED,
1965                         log);
1966         if (start < 0)
1967             return start;
1968 
1969         at = __add_action(sfa, key_type, NULL, len, log);
1970         if (IS_ERR(at))
1971             return PTR_ERR(at);
1972 
1973         memcpy(nla_data(at), nla_data(ovs_key), key_len); /* Key\&. */
1974         memset(nla_data(at) + key_len, 0xff, key_len);    /* Mask\&. */
1975         /* Clear non-writeable bits from otherwise writeable fields\&. */
1976         if (key_type == OVS_KEY_ATTR_IPV6) {
1977             struct ovs_key_ipv6 *mask = nla_data(at) + key_len;
1978 
1979             mask->ipv6_label &= htonl(0x000FFFFF);
1980         }
1981         add_nested_action_end(*sfa, start);
1982     }
1983 
1984     return 0;
1985 }
.fi
.SS "static int validate_userspace (const struct nlattr * attr)\fC [static]\fP"

.PP
.nf
1988 {
1989     static const struct nla_policy userspace_policy[OVS_USERSPACE_ATTR_MAX + 1] = {
1990         [OVS_USERSPACE_ATTR_PID] = {\&.type = NLA_U32 },
1991         [OVS_USERSPACE_ATTR_USERDATA] = {\&.type = NLA_UNSPEC },
1992         [OVS_USERSPACE_ATTR_EGRESS_TUN_PORT] = {\&.type = NLA_U32 },
1993     };
1994     struct nlattr *a[OVS_USERSPACE_ATTR_MAX + 1];
1995     int error;
1996 
1997     error = nla_parse_nested(a, OVS_USERSPACE_ATTR_MAX,
1998                  attr, userspace_policy);
1999     if (error)
2000         return error;
2001 
2002     if (!a[OVS_USERSPACE_ATTR_PID] ||
2003         !nla_get_u32(a[OVS_USERSPACE_ATTR_PID]))
2004         return -EINVAL;
2005 
2006     return 0;
2007 }
.fi
.SS "static int vxlan_opt_to_nlattr (struct sk_buff * skb, const void * tun_opts, int swkey_tun_opts_len)\fC [static]\fP"

.PP
.nf
628 {
629     const struct ovs_vxlan_opts *opts = tun_opts;
630     struct nlattr *nla;
631 
632     nla = nla_nest_start(skb, OVS_TUNNEL_KEY_ATTR_VXLAN_OPTS);
633     if (!nla)
634         return -EMSGSIZE;
635 
636     if (nla_put_u32(skb, OVS_VXLAN_EXT_GBP, opts->gbp) < 0)
637         return -EMSGSIZE;
638 
639     nla_nest_end(skb, nla);
640     return 0;
641 }
.fi
.SS "static int vxlan_tun_opt_from_nlattr (const struct nlattr * a, struct \fBsw_flow_match\fP * match, \fBbool\fP is_mask, \fBbool\fP log)\fC [static]\fP"

.PP
.nf
475 {
476     struct nlattr *tb[OVS_VXLAN_EXT_MAX+1];
477     unsigned long opt_key_offset;
478     struct ovs_vxlan_opts opts;
479     int err;
480 
481     BUILD_BUG_ON(sizeof(opts) > sizeof(match->key->tun_opts));
482 
483     err = nla_parse_nested(tb, OVS_VXLAN_EXT_MAX, a, vxlan_opt_policy);
484     if (err < 0)
485         return err;
486 
487     memset(&opts, 0, sizeof(opts));
488 
489     if (tb[OVS_VXLAN_EXT_GBP])
490         opts\&.gbp = nla_get_u32(tb[OVS_VXLAN_EXT_GBP]);
491 
492     if (!is_mask)
493         SW_FLOW_KEY_PUT(match, tun_opts_len, sizeof(opts), false);
494     else
495         SW_FLOW_KEY_PUT(match, tun_opts_len, 0xff, true);
496 
497     opt_key_offset = TUN_METADATA_OFFSET(sizeof(opts));
498     SW_FLOW_KEY_MEMCPY_OFFSET(match, opt_key_offset, &opts, sizeof(opts),
499                   is_mask);
500     return 0;
501 }
.fi
.SH "Variable Documentation"
.PP 
.SS "const struct \fBovs_len_tbl\fP ovs_key_lens[\fBOVS_KEY_ATTR_MAX\fP+1]\fC [static]\fP"
\fBInitial value:\fP
.PP
.nf
= {
    [OVS_KEY_ATTR_ENCAP]     = { \&.len = OVS_ATTR_NESTED },
    [OVS_KEY_ATTR_PRIORITY]  = { \&.len = sizeof(u32) },
    [OVS_KEY_ATTR_IN_PORT]   = { \&.len = sizeof(u32) },
    [OVS_KEY_ATTR_SKB_MARK]  = { \&.len = sizeof(u32) },
    [OVS_KEY_ATTR_ETHERNET]  = { \&.len = sizeof(struct ovs_key_ethernet) },
    [OVS_KEY_ATTR_VLAN]  = { \&.len = sizeof(__be16) },
    [OVS_KEY_ATTR_ETHERTYPE] = { \&.len = sizeof(__be16) },
    [OVS_KEY_ATTR_IPV4]  = { \&.len = sizeof(struct ovs_key_ipv4) },
    [OVS_KEY_ATTR_IPV6]  = { \&.len = sizeof(struct ovs_key_ipv6) },
    [OVS_KEY_ATTR_TCP]   = { \&.len = sizeof(struct ovs_key_tcp) },
    [OVS_KEY_ATTR_TCP_FLAGS] = { \&.len = sizeof(__be16) },
    [OVS_KEY_ATTR_UDP]   = { \&.len = sizeof(struct ovs_key_udp) },
    [OVS_KEY_ATTR_SCTP]  = { \&.len = sizeof(struct ovs_key_sctp) },
    [OVS_KEY_ATTR_ICMP]  = { \&.len = sizeof(struct ovs_key_icmp) },
    [OVS_KEY_ATTR_ICMPV6]    = { \&.len = sizeof(struct ovs_key_icmpv6) },
    [OVS_KEY_ATTR_ARP]   = { \&.len = sizeof(struct ovs_key_arp) },
    [OVS_KEY_ATTR_ND]    = { \&.len = sizeof(struct ovs_key_nd) },
    [OVS_KEY_ATTR_RECIRC_ID] = { \&.len = sizeof(u32) },
    [OVS_KEY_ATTR_DP_HASH]   = { \&.len = sizeof(u32) },
    [OVS_KEY_ATTR_TUNNEL]    = { \&.len = OVS_ATTR_NESTED,
                     \&.next = ovs_tunnel_key_lens, },
    [OVS_KEY_ATTR_MPLS]  = { \&.len = sizeof(struct ovs_key_mpls) },
}
.fi
.SS "const struct \fBovs_len_tbl\fP ovs_tunnel_key_lens[\fBOVS_TUNNEL_KEY_ATTR_MAX\fP+1]\fC [static]\fP"
\fBInitial value:\fP
.PP
.nf
= {
    [OVS_TUNNEL_KEY_ATTR_ID]        = { \&.len = sizeof(u64) },
    [OVS_TUNNEL_KEY_ATTR_IPV4_SRC]      = { \&.len = sizeof(u32) },
    [OVS_TUNNEL_KEY_ATTR_IPV4_DST]      = { \&.len = sizeof(u32) },
    [OVS_TUNNEL_KEY_ATTR_TOS]       = { \&.len = 1 },
    [OVS_TUNNEL_KEY_ATTR_TTL]       = { \&.len = 1 },
    [OVS_TUNNEL_KEY_ATTR_DONT_FRAGMENT] = { \&.len = 0 },
    [OVS_TUNNEL_KEY_ATTR_CSUM]      = { \&.len = 0 },
    [OVS_TUNNEL_KEY_ATTR_TP_SRC]        = { \&.len = sizeof(u16) },
    [OVS_TUNNEL_KEY_ATTR_TP_DST]        = { \&.len = sizeof(u16) },
    [OVS_TUNNEL_KEY_ATTR_OAM]       = { \&.len = 0 },
    [OVS_TUNNEL_KEY_ATTR_GENEVE_OPTS]   = { \&.len = OVS_ATTR_NESTED },
    [OVS_TUNNEL_KEY_ATTR_VXLAN_OPTS]    = { \&.len = OVS_ATTR_NESTED },
}
.fi
.SS "const struct nla_policy vxlan_opt_policy[\fBOVS_VXLAN_EXT_MAX\fP+1]\fC [static]\fP"
\fBInitial value:\fP
.PP
.nf
= {
    [OVS_VXLAN_EXT_GBP] = { \&.type = NLA_U32 },
}
.fi
.SH "Author"
.PP 
Generated automatically by Doxygen for ovs datapath from the source code\&.
