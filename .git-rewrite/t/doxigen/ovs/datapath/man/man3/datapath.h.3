.TH "/home/vladn/git/ovs/datapath/datapath.h" 3 "Mon Aug 17 2015" "ovs datapath" \" -*- nroff -*-
.ad l
.nh
.SH NAME
/home/vladn/git/ovs/datapath/datapath.h \- 
.SH SYNOPSIS
.br
.PP
\fC#include <asm/page\&.h>\fP
.br
\fC#include <linux/kernel\&.h>\fP
.br
\fC#include <linux/mutex\&.h>\fP
.br
\fC#include <linux/netdevice\&.h>\fP
.br
\fC#include <linux/skbuff\&.h>\fP
.br
\fC#include <linux/u64_stats_sync\&.h>\fP
.br
\fC#include 'compat\&.h'\fP
.br
\fC#include 'flow\&.h'\fP
.br
\fC#include 'flow_table\&.h'\fP
.br
\fC#include 'vlan\&.h'\fP
.br
\fC#include 'vport\&.h'\fP
.br

.SS "Data Structures"

.in +1c
.ti -1c
.RI "struct \fBdp_stats_percpu\fP"
.br
.ti -1c
.RI "struct \fBdatapath\fP"
.br
.ti -1c
.RI "struct \fBovs_skb_cb\fP"
.br
.ti -1c
.RI "struct \fBdp_upcall_info\fP"
.br
.ti -1c
.RI "struct \fBovs_net\fP"
.br
.in -1c
.SS "Macros"

.in +1c
.ti -1c
.RI "#define \fBDP_MAX_PORTS\fP   \fBUSHRT_MAX\fP"
.br
.ti -1c
.RI "#define \fBDP_VPORT_HASH_BUCKETS\fP   1024"
.br
.ti -1c
.RI "#define \fBSAMPLE_ACTION_DEPTH\fP   3"
.br
.ti -1c
.RI "#define \fBOVS_CB\fP(skb)   ((struct \fBovs_skb_cb\fP *)(skb)->cb)"
.br
.ti -1c
.RI "#define \fBlockdep_ovsl_is_held\fP()   1"
.br
.ti -1c
.RI "#define \fBASSERT_OVSL\fP()   WARN_ON(!\fBlockdep_ovsl_is_held\fP())"
.br
.ti -1c
.RI "#define \fBovsl_dereference\fP(p)   \fBrcu_dereference_protected\fP(p, \fBlockdep_ovsl_is_held\fP())"
.br
.ti -1c
.RI "#define \fBrcu_dereference_ovsl\fP(p)   \fBrcu_dereference_check\fP(p, \fBlockdep_ovsl_is_held\fP())"
.br
.ti -1c
.RI "#define \fBOVS_NLERR\fP(logging_allowed,  fmt, \&.\&.\&.)"
.br
.in -1c
.SS "Functions"

.in +1c
.ti -1c
.RI "void \fBovs_lock\fP (void)"
.br
.ti -1c
.RI "void \fBovs_unlock\fP (void)"
.br
.ti -1c
.RI "static struct net * \fBovs_dp_get_net\fP (const struct \fBdatapath\fP *dp)"
.br
.ti -1c
.RI "static void \fBovs_dp_set_net\fP (struct \fBdatapath\fP *dp, struct net *net)"
.br
.ti -1c
.RI "struct \fBvport\fP * \fBovs_lookup_vport\fP (const struct \fBdatapath\fP *dp, u16 port_no)"
.br
.ti -1c
.RI "static struct \fBvport\fP * \fBovs_vport_rcu\fP (const struct \fBdatapath\fP *dp, int port_no)"
.br
.ti -1c
.RI "static struct \fBvport\fP * \fBovs_vport_ovsl_rcu\fP (const struct \fBdatapath\fP *dp, int port_no)"
.br
.ti -1c
.RI "static struct \fBvport\fP * \fBovs_vport_ovsl\fP (const struct \fBdatapath\fP *dp, int port_no)"
.br
.ti -1c
.RI "void \fBovs_dp_process_packet\fP (struct sk_buff *skb, struct \fBsw_flow_key\fP *key)"
.br
.ti -1c
.RI "void \fBovs_dp_detach_port\fP (struct \fBvport\fP *)"
.br
.ti -1c
.RI "int \fBovs_dp_upcall\fP (struct \fBdatapath\fP *, struct sk_buff *, const struct \fBsw_flow_key\fP *, const struct \fBdp_upcall_info\fP *)"
.br
.ti -1c
.RI "const char * \fBovs_dp_name\fP (const struct \fBdatapath\fP *dp)"
.br
.ti -1c
.RI "struct sk_buff * \fBovs_vport_cmd_build_info\fP (struct \fBvport\fP *, u32 pid, u32 seq, u8 cmd)"
.br
.ti -1c
.RI "int \fBovs_execute_actions\fP (struct \fBdatapath\fP *dp, struct sk_buff *skb, const struct \fBsw_flow_actions\fP *, struct \fBsw_flow_key\fP *)"
.br
.ti -1c
.RI "void \fBovs_dp_notify_wq\fP (struct work_struct *work)"
.br
.ti -1c
.RI "int \fBaction_fifos_init\fP (void)"
.br
.ti -1c
.RI "void \fBaction_fifos_exit\fP (void)"
.br
.in -1c
.SS "Variables"

.in +1c
.ti -1c
.RI "int \fBovs_net_id\fP"
.br
.ti -1c
.RI "struct notifier_block \fBovs_dp_device_notifier\fP"
.br
.ti -1c
.RI "struct \fBgenl_family\fP \fBdp_vport_genl_family\fP"
.br
.ti -1c
.RI "struct genl_multicast_group \fBovs_dp_vport_multicast_group\fP"
.br
.in -1c
.SH "Macro Definition Documentation"
.PP 
.SS "#define ASSERT_OVSL()   WARN_ON(!\fBlockdep_ovsl_is_held\fP())"

.SS "#define DP_MAX_PORTS   \fBUSHRT_MAX\fP"

.SS "#define DP_VPORT_HASH_BUCKETS   1024"

.SS "#define lockdep_ovsl_is_held()   1"

.SS "#define OVS_CB(skb)   ((struct \fBovs_skb_cb\fP *)(skb)->cb)"

.SS "#define OVS_NLERR(logging_allowed, fmt,  \&.\&.\&.)"
\fBValue:\fP
.PP
.nf
do {                                \
    if (logging_allowed && net_ratelimit())         \
        pr_info("netlink: " fmt "\n", ##__VA_ARGS__);   \
} while (0)
.fi
.SS "#define ovsl_dereference(p)   \fBrcu_dereference_protected\fP(p, \fBlockdep_ovsl_is_held\fP())"

.SS "#define rcu_dereference_ovsl(p)   \fBrcu_dereference_check\fP(p, \fBlockdep_ovsl_is_held\fP())"

.SS "#define SAMPLE_ACTION_DEPTH   3"

.SH "Function Documentation"
.PP 
.SS "void action_fifos_exit (void)"

.PP
.nf
1016 {
1017     free_percpu(action_fifos);
1018 }
.fi
.SS "int action_fifos_init (void)"

.PP
.nf
1007 {
1008     action_fifos = alloc_percpu(struct action_fifo);
1009     if (!action_fifos)
1010         return -ENOMEM;
1011 
1012     return 0;
1013 }
.fi
.SS "void ovs_dp_detach_port (struct \fBvport\fP *)"

.PP
.nf
249 {
250     ASSERT_OVSL();
251 
252     /* First drop references to device\&. */
253     hlist_del_rcu(&p->dp_hash_node);
254 
255     /* Then destroy it\&. */
256     ovs_vport_del(p);
257 }
.fi
.SS "static struct net* ovs_dp_get_net (const struct \fBdatapath\fP * dp)\fC [static]\fP"

.PP
.nf
158 {
159     return read_pnet(&dp->net);
160 }
.fi
.SS "const char* ovs_dp_name (const struct \fBdatapath\fP * dp)"

.PP
.nf
179 {
180     struct vport *vport = ovs_vport_ovsl_rcu(dp, OVSP_LOCAL);
181     return vport->ops->get_name(vport);
182 }
.fi
.SS "void ovs_dp_notify_wq (struct work_struct * work)"

.PP
.nf
50 {
51     struct ovs_net *ovs_net = container_of(work, struct ovs_net, dp_notify_work);
52     struct datapath *dp;
53 
54     ovs_lock();
55     list_for_each_entry(dp, &ovs_net->dps, list_node) {
56         int i;
57 
58         for (i = 0; i < DP_VPORT_HASH_BUCKETS; i++) {
59             struct vport *vport;
60             struct hlist_node *n;
61 
62             hlist_for_each_entry_safe(vport, n, &dp->ports[i], dp_hash_node) {
63                 struct netdev_vport *netdev_vport;
64 
65                 if (vport->ops->type != OVS_VPORT_TYPE_NETDEV)
66                     continue;
67 
68                 netdev_vport = netdev_vport_priv(vport);
69                 if (!(ovs_netdev_get_vport(netdev_vport->dev)))
70                     dp_detach_port_notify(vport);
71             }
72         }
73     }
74     ovs_unlock();
75 }
.fi
.SS "void ovs_dp_process_packet (struct sk_buff * skb, struct \fBsw_flow_key\fP * key)"

.PP
.nf
261 {
262     const struct vport *p = OVS_CB(skb)->input_vport;
263     struct datapath *dp = p->dp;
264     struct sw_flow *flow;
265     struct sw_flow_actions *sf_acts;
266     struct dp_stats_percpu *stats;
267     u64 *stats_counter;
268     u32 n_mask_hit;
269 
270     stats = this_cpu_ptr(dp->stats_percpu);
271 
272     /* Look up flow\&. */
273     flow = ovs_flow_tbl_lookup_stats(&dp->table, key, skb_get_hash(skb),
274                      &n_mask_hit);
275     if (unlikely(!flow)) {
276         struct dp_upcall_info upcall;
277         int error;
278 
279         memset(&upcall, 0, sizeof(upcall));
280         upcall\&.cmd = OVS_PACKET_CMD_MISS;
281         upcall\&.portid = ovs_vport_find_upcall_portid(p, skb);
282         error = ovs_dp_upcall(dp, skb, key, &upcall);
283         if (unlikely(error))
284             kfree_skb(skb);
285         else
286             consume_skb(skb);
287         stats_counter = &stats->n_missed;
288         goto out;
289     }
290 
291     ovs_flow_stats_update(flow, key->tp\&.flags, skb);
292     sf_acts = rcu_dereference(flow->sf_acts);
293     ovs_execute_actions(dp, skb, sf_acts, key);
294 
295     stats_counter = &stats->n_hit;
296 
297 out:
298     /* Update datapath statistics\&. */
299     u64_stats_update_begin(&stats->syncp);
300     (*stats_counter)++;
301     stats->n_mask_hit += n_mask_hit;
302     u64_stats_update_end(&stats->syncp);
303 }
.fi
.SS "static void ovs_dp_set_net (struct \fBdatapath\fP * dp, struct net * net)\fC [inline]\fP, \fC [static]\fP"

.PP
.nf
163 {
164     write_pnet(&dp->net, net);
165 }
.fi
.SS "int ovs_dp_upcall (struct \fBdatapath\fP *, struct sk_buff *, const struct \fBsw_flow_key\fP *, const struct \fBdp_upcall_info\fP *)"

.PP
.nf
308 {
309     struct dp_stats_percpu *stats;
310     int err;
311 
312     if (upcall_info->portid == 0) {
313         err = -ENOTCONN;
314         goto err;
315     }
316 
317     if (!skb_is_gso(skb))
318         err = queue_userspace_packet(dp, skb, key, upcall_info);
319     else
320         err = queue_gso_packets(dp, skb, key, upcall_info);
321     if (err)
322         goto err;
323 
324     return 0;
325 
326 err:
327     stats = this_cpu_ptr(dp->stats_percpu);
328 
329     u64_stats_update_begin(&stats->syncp);
330     stats->n_lost++;
331     u64_stats_update_end(&stats->syncp);
332 
333     return err;
334 }
.fi
.SS "int ovs_execute_actions (struct \fBdatapath\fP * dp, struct sk_buff * skb, const struct \fBsw_flow_actions\fP *, struct \fBsw_flow_key\fP *)"

.PP
.nf
977 {
978     int level = this_cpu_read(exec_actions_level);
979     int err;
980 
981     if (unlikely(level >= EXEC_ACTIONS_LEVEL_LIMIT)) {
982         if (net_ratelimit())
983             pr_warn("%s: packet loop detected, dropping\&.\n",
984                 ovs_dp_name(dp));
985 
986         kfree_skb(skb);
987         return -ELOOP;
988     }
989 
990     this_cpu_inc(exec_actions_level);
991     err = do_execute_actions(dp, skb, key,
992                  acts->actions, acts->actions_len);
993 
994     if (!level)
995         process_deferred_actions(dp);
996 
997     this_cpu_dec(exec_actions_level);
998 
999     /* This return status currently does not reflect the errors
1000      * encounted during deferred actions execution\&. Probably needs to
1001      * be fixed in the future\&.
1002      */
1003     return err;
1004 }
.fi
.SS "void ovs_lock (void)"

.PP
.nf
121 {
122     mutex_lock(&ovs_mutex);
123 }
.fi
.SS "struct \fBvport\fP* ovs_lookup_vport (const struct \fBdatapath\fP * dp, u16 port_no)"

.PP
.nf
221 {
222     struct vport *vport;
223     struct hlist_head *head;
224 
225     head = vport_hash_bucket(dp, port_no);
226     hlist_for_each_entry_rcu(vport, head, dp_hash_node) {
227         if (vport->port_no == port_no)
228             return vport;
229     }
230     return NULL;
231 }
.fi
.SS "void ovs_unlock (void)"

.PP
.nf
126 {
127     mutex_unlock(&ovs_mutex);
128 }
.fi
.SS "struct sk_buff* ovs_vport_cmd_build_info (struct \fBvport\fP *, u32 pid, u32 seq, u8 cmd)"

.PP
.nf
1848 {
1849     struct sk_buff *skb;
1850     int retval;
1851 
1852     skb = nlmsg_new(NLMSG_DEFAULT_SIZE, GFP_ATOMIC);
1853     if (!skb)
1854         return ERR_PTR(-ENOMEM);
1855 
1856     retval = ovs_vport_cmd_fill_info(vport, skb, portid, seq, 0, cmd);
1857     BUG_ON(retval < 0);
1858 
1859     return skb;
1860 }
.fi
.SS "static struct \fBvport\fP* ovs_vport_ovsl (const struct \fBdatapath\fP * dp, int port_no)\fC [static]\fP"

.PP
.nf
182 {
183     ASSERT_OVSL();
184     return ovs_lookup_vport(dp, port_no);
185 }
.fi
.SS "static struct \fBvport\fP* ovs_vport_ovsl_rcu (const struct \fBdatapath\fP * dp, int port_no)\fC [static]\fP"

.PP
.nf
176 {
177     WARN_ON_ONCE(!rcu_read_lock_held() && !lockdep_ovsl_is_held());
178     return ovs_lookup_vport(dp, port_no);
179 }
.fi
.SS "static struct \fBvport\fP* ovs_vport_rcu (const struct \fBdatapath\fP * dp, int port_no)\fC [static]\fP"

.PP
.nf
170 {
171     WARN_ON_ONCE(!rcu_read_lock_held());
172     return ovs_lookup_vport(dp, port_no);
173 }
.fi
.SH "Variable Documentation"
.PP 
.SS "struct \fBgenl_family\fP dp_vport_genl_family"

.SS "struct notifier_block ovs_dp_device_notifier"

.SS "struct genl_multicast_group ovs_dp_vport_multicast_group"

.SS "int ovs_net_id"

.SH "Author"
.PP 
Generated automatically by Doxygen for ovs datapath from the source code\&.
